---
format: 
  revealjs: 
    # self-contained: true
    theme: [default, theme/theme.scss]
    footer: "R Aplicado a los Proyectos de Investigación - Sesión 8"
    logo: img/icon-512-insnsb.jpg
    transition: convex
    background-transition: zoom
    incremental: false
    slide-number: c/t
    preview-links: true
    # width: 1920
    # height: 1080
    height: 900
    width: 1600
    # parallax-background-image: img/bg-ietsi-slide-first.png
    # parallax-background-size: "1920px 1080px"
    chalkboard: true
    code-block-background: true
    code-block-border-left: "#31BAE9"
    highlight-style: ayu-dark
    echo: true
    multiplex: true
    touch: true
    auto-stretch: true
    link-external-icon: true
    link-external-newwindow: true
    self-contained-math: true
    
from: markdown+emoji
execute:
  echo: true
filters:
  - reveal-auto-agenda
  - grouped-tabsets
auto-agenda:
  bullets: numbered
  heading: Agenda
---

\

\

<h1>Sesión 8</h1>

<h2>[Curso: R Aplicado a los Proyectos de Investigación]{.plo}</h2>

<hr>

<h3>[Percy Soto-Becerra, M.D., M.Sc(c)]{.negro}</h3>

<h4>[InkaStats Data Science Solutions \| Medical Branch]{.negro}</h4>

<h4>[2022-10-19]{.negro}</h4>

`r fontawesome::fa("github", "black")`   <https://github.com/psotob91>

![](img/social-image-f22.png){.absolute top="390" left="950" width="600"}

```{r}
#| echo: false
#| output: false

# Removing all objects including loaded libraries
rm(list = ls(all = TRUE))
gc()

# Installing and loading packages
if (!require("pacman")) {
  install.packages("pacman")
}

pacman::p_unload("all") # Unloading all package except base

pacman::p_load(tidyverse, 
               tibble, 
               labelled, 
               pander, 
               gt, 
               kableExtra, 
               DT, 
               haven, 
               skimr, 
               Hmisc, 
               janitor, 
               rio, 
               gtsummary, 
               gt, 
               flextable, 
               kableExtra, 
               readxl, 
               rstatix, 
               medicaldata, 
               ggpubr, 
               car, 
               performance,
               see, 
               lmtest, 
               sandwich, 
               splines2, 
               plotly, 
               glue) # Loading packages

md_visit <- import("rwm5yr.dta") %>% 
  characterize()

```

# Introducción al modelado de regresión

## Análisis de regresión

> Conjunto de técnicas estadística para estimar la relación entre variables.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion1.png")
```

## Modelos de regresión multivariable

> Los modelos de regresión multivariable modelan una sola variable dependiente en función de una o más variables independientes.

- El desenlace define el tipo de regresión multivariable.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion2.png")
```

## ¿Para qué usamos los modelos de regresión?

-   Según `STRATOS` podemos usar regresión para 3 propósitos diferentes:

    -   <FONT size='6'>Descripción\*</FONT>

    -   <FONT size='6'>Predicción</FONT>

    -   <FONT size='6'>Explicación</FONT>

## Propósitos del modelamiento

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/modelos1.png")
```

::: aside
<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>
:::

## Propósitos del modelamiento (cont.)

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/modelos2.png")
```

::: aside
<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>
:::

## ¿Para qué usamos los modelos de regresión? (cont.)

-   Este curso se centrará solamente en algunas aplicaciones.

-   No abordaremos modelos de regresión para desarrollar modelos o reglas de predicción clínica.

-   Tampoco para métodos de inferencia causal robusta.

::: panel-tabset
### Descripción

-   Evaluación de la magnitud de desigualdades, magnitud de brechas, etc.
-   "Factores asociados..:" No necesariamente importa que los factores sean causales.

### Explicación

-   "Efecto / Efectividad / Impacto": Busca estimar efectos causales.
-   Explorar potenciales factores causales... (puede clasificarse dentro de descripción)

### Predicción

-   Factores pronóstico o predictores de...": Identifican predictores de interés que luego alimenten mdelos predictivos.
-   Modelos de predicción: Predicción para diagnóstico y pronóstico.
:::

# Modelo de Regresión Lineal Simple

## Regresión Lineal

> Método estadístico que modela la `relación` entre una `variable continua (dependiente)` y otras `variables (independientes)`.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-lineal.png")
```

## Relación entre dos variables

::: columns
::: {.column width="30%"}
-   $Y$ es `variable resultado` (*outcome*), respuesta o dependiente.

-   $X$ es una `variable explicativa`, predictora o regresora.

-   En la figura, a mayor valor de $X$, mayor valor de $Y$.

```{r}
#| echo: false
set.seed(123)
x = rnorm(500, 0, 1)
y = 4 * x + rnorm(50, 0, 2)

datos <- data.frame(
  x = x, 
  y = y)
```
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## ¿Cómo podemos resumir la relación entre ambas variables?

::: columns
::: {.column width="30%"}
-   Podemos tratar de dibujar una `línea recta` que `resuma` la relación.

-   Existen `infinitas rectas posibles` que podríamos trazar: ¿Cuál elegir?
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_abline(aes(x = x, y = y), intercept = -1, slope = 1, colour = "red") + 
  geom_abline(aes(x = x, y = y), intercept = 0.07, slope = 4.4 , colour = "green") + 
    geom_abline(aes(x = x, y = y), intercept = 0.07, slope = 3.9 , colour = "orange") + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## ¿Cómo podemos resumir la relación entre ambas variables? (cont.)

::: columns
::: {.column width="30%"}
-   Una opción sería elegir una `recta` que pase por el `valor más representativo` del $y_i$ en cada valor fijo de $x_1$.
    -   Una `recta` que `conecte` los `promedios condicionados` en $x_1$
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## Anatomía de la RLS {.scrollable}

-   Entonces, el modelo de `regresión lineal simple` se puede expresar de la siguiente manera:


$$y_i = \underbrace{\beta_0 + \beta_1x_{1i}}_{\text{componente}  \\ \text{sistemático}} + \underbrace{\epsilon_i}_{\text{componente} \\ \text{aleatorio}}$$

- El `componente sistemático` describe  la media de $y_i$ en cada valor fijo de $x_{1i}$: `Media condicionada de y en x`.

    - Pero el promedio no existe, los que existen son los individuos.

- El `componente aleatorio` describe la variación de los individuos alrededor de cada media condiciona de y:

    - Se asume cierta distribución conocida.

## Componente sistemático {.scrollable}

-    Formalmente hablando, para cada `observación` $i$ en la población, podemos `relacionar` el `valor esperado` (media) $E[y_i]$ de $y_i$ (también llamado $\mu_i$) con la `variable explicativa` $x_{1i}$ mediante la siguiente `ecuación lineal`:

$$E[Y | X_1 = x_{1i}] = E[y_i] =  \mu_i = \beta_0 + \beta_1x_{1i}$$


-   Donde:
    -   $y_i$ son realizaciones de `variables aleatorias` independientes e idénticamente distribuidas (`i.i.d`)
    -   $x_1$ es una variable cuyas valores son fijos y conocidos: $x_1i$:
    -   $\beta_0$ y $\beta_1$ son `parámetros desconocidos` de una superpoblación infinita.

## Algunasn notas sobre el componente sistemático {.scrollable}

:::{.callout-note collapse=false appearance='default' icon=false}
## $x_1$ es fijo
-   Se asume se miden sin error.
-   No importa su distribución.
:::

:::{.callout-note collapse=false appearance='default' icon=false}
## $\beta_0$ y $\beta_1$
-   Llamados `coeficientes de regresión` y son una `medida de asociación`.
-   Es lo que `queremos estimar` con los datos de la muestra!
:::
    
:::{.callout-warning collapse=false appearance='default' icon=true}
## Advertencia
-   Notar que el `componente sistemático` solo `relaciona` el `promedio condicionado` de $y_i$ con las `variables explicativas`, NO con los valores individuales.
-   Esta es una manera de obtener una medida que resuma las relaciones individuales en una sola medida.
:::
    

## Componente aleatorio {.scrollable}

-   Para poder relacionar completamente los valores individuales con la ecuación de regersión se agrega un término de error $\epsilon$, el cual se obtiene de restar el valor observado $y_i$ con el valor esperado de este ($\mu_i$):

$$\epsilon_i = y_i - \mu_i$$

-   El problema es que el término de error $\epsilon_i$ no puede predecirse ni estimarse con los datos, se considera que es el `componente no explicado` por la variable independiente.

    -   Para lidiar con este, se asume que su comportamiento puede predecirse a nivel probabilístico: Se asume una distribución de este.
    -   El error $\epsilon_i$ hereda la distribución de probabilidad de $y_i$.

## Componente aleatorio (cont.) {.scrollable}

-   Por lo tanto, el valor individual de cada $y_i$ puede ser denotado por la siguiente expresión:

$$y_i = \beta_0 + \beta_1x_{1i} + \epsilon_i$$

-   Para hacer inferencia estadística, a menudo se asume lo siguiente:

$$y_i \sim N(\beta_0 + \beta_1x_{1i}, \sigma^2)$$

$$\epsilon_i \sim N(0, \sigma^2) $$ 

## En resumen

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-normal.png")
```

## Estimación de ecuación de regresión

-   En la práctica no conocemos los valores de los parámetros, así que los estimamos de nuestros datos.

![](img/regresion-parametro-estim.png)

## ¿Cómo estimamos la ecuación lineal que mejor ajusta a los datos observados?

-   Usamos `métodos numéricos`:

    -   `Método de Mínimos Cuadrados Ordinarios (MCO)`

    -   Método de `Máxima Verosimilitud (MV)`

-   MCO y MV son equivalentes para el caso de la regresión lineal normal.

- El `estimador MCO` es `insesgado`, no importa la distribución de $y_i$ o $\epsilon_i$.

- El estimador MCO tiene `mínima varianza` si y solo si:

    - Hay `independencia de observaciones`.
    - Hay `normalidad`.

## Algunas notas sobre normalidad

-   No es necesario que $\epsilon_i$ o  sigan una distribución normal para que los coeficientes de regresión $\beta$ puedan estimarse de manera puntual.

-   Sin embargo, para estimar el `valor p` o los `intervalos de confianza` mediante `inferencia clásica` sí se necesita asumir una distribución conocida. 

    - El modelo de regresión lineal normal asume normalidad de $y_i$ y $\epsilon_i$.

    -   Sin embargo, el modelo es robusto a desviaciones leves/moderadas de la normalidad cuando se cumple el TLC (número de observaciones grande).

-   Otros enfoques para inferencia flexibilizan este supuesto: 

    - Bootstrap, varianza robusta, modelo lineal generalizado que asume otras distribuciones, etc.


## Regresión Lineal Simple sobre variable explicativa categórica


:::: {.columns}

::: {.column width='40%'}
-   Las `variables categóricas` no son continuas, en cambio son discretas y asumen solo unos cuantos valores.

-   ¿Cómo estimar una medida de asociación cuando la variable explicativa es categórica?

- Veamos el caso binario.

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
y <- 4 * x + rnorm(50, 0, 2)

datos <- data.frame(
  x1 = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2 = x, 
  y = y)
```
:::

::: {.column width='60%'}

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
datos %>% 
  ggplot(aes(x = x1, y = y)) + 
  geom_point() + 
  theme_bw()
```

:::

::::


## Regresión Lineal Simple sobre variable explicativa categórica (cont.)

:::: {.columns}

::: {.column width='40%'}
-   Si la variable es `binaria`, asignamos a una categoría el `valor de 1` y a otra el `valor de 0`.

    -   Asumiremos que la variable categórica es numérica para los efectos de todo cálculo.

    -   Sin embargo, la interpretación se centrará en la comparación de categorías 0 y 1, nunca se interperará valores intermedios porquen o existen.
:::

::: {.column width='60%'}

```{r}
#| echo: false
datos %>% 
  ggplot(aes(x = x2, y = y)) +   
  geom_smooth(method = "lm", se = FALSE) + 
  geom_point() + 
  theme_bw()
```

:::

::::


# Regresión Lineal Simple en R 

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(50, 15, 1)
y <- 10 * x - 2 * z + rnorm(50, 0, 2)

datos1 <- data.frame(
  x1 = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2 = x, 
  x3 = z, 
  y = y)
```

## lm() paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
lm(y ~ x1, data = datos)
```

-   Se usa la función `lm()` de R base. Sin embargo, la salida de esta no es muy informativa:

    - Solo reportar coefiecientes de regresión (componente sistemático)
:::

::: {.column width='60%'}
```{r}
#| echo: false
lm(y ~ x1, data = datos)
```
:::

::::


## lm() paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
mod <- lm(y ~ x1, data = datos)
```

-   Se usa la función `lm()` de R base. Sin embargo, la salida de esta no es muy informativa:
    
-   El modelo puede guardarse para realizar más operaciones sobre este. Por ejemplo, mejorar la salida.

:::

::: {.column width='60%'}
```{r}
#| echo: false
mod <- lm(y ~ x1, data = datos)
```
:::

::::

## lm() paso a paso {auto-animate=true}


:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
mod <- lm(y ~ x1, data = datos)
summary(mod)
```

-   Se usa la función [lm()]{.verde-h3} de R base. Sin embargo, la salida de esta no es muy informativa:
    
-   El modelo puede guardarse para realizar más operaciones sobre este. Por ejemplo, mejorar la salida.   

- Podemos usar [summary()]{.verde-h3} para ver resultados detallados.


:::

::: {.column width='60%'}
```{r}
#| echo: false
mod <- lm(y ~ x1, data = datos)
summary(mod)
```
:::

::::

## Interpretación de salida de RLS {.scrollable}

::: panel-tabset
### Covariable numérica

-   Usamos la función lm():

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(1000, 15, 1)
y <- -10 * x + 1.3 * z + rnorm(100, 0, 2)

datos2 <- data.frame(
  x1_tto = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2_ttonum = x, 
  x3_peso_inicial = z, 
  y_peso_final = y)
```

```{r}
mod <- lm(y_peso_final ~ x3_peso_inicial, data = datos2)
summary(mod)
```

-   El modelo estimado sería el siguiente:

$$y\_pesofinal = -5.4317 + 1.3447*x3\_pesoinicial + \epsilon_i$$

$$\epsilon_i \sim Normal(0, 5.535^2)$$

-   Usando el paquete `{broom}` y su función `tidy()` podemos obtener también los intervalos de confianza:

```{r}
library(broom)
mod %>% 
  tidy(conf.int = TRUE) 
```

-   Interpretación:

    -   $\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor.

    -   $\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.43 kg (IC95% 1.00 a 1.69; p \< 0.001).

### Covariable categórica

-   Usamos la función lm():

```{r}
mod <- lm(y_peso_final ~ x1_tto, data = datos2)
summary(mod)
```

-   Usando tidy de broom:

```{r}
mod %>% 
  tidy(conf.int = TRUE) 
```

-   Interpretación:

    -   $\beta_0$ (Intercept): A menudo no se interpreta. Es el valor promedio de $y_i$ cuando los valores de $x$ son cero. En este caso, cuando el tratamien es cero (placebo). ¿Esto es posible?, sí es posible pero no es de ayuda para modelos explicativos, por lo que no se interpreta.

    -   $\beta1$ x1Tratamiento Nuevo: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.23 kg menor que el de quienes recibieron placebo (Dif. medias = -10.23; IC95% -10.54 a -9.92; p \< 0.001).
:::

# Regresión Lineal Múltiple

## Regresión Lineal Múltiple {.scrollable}

> El modelo de regresión lineal múltiple generaliza la RLS permitiendo evaluar la relación de varias covariables explicativas $x$ sobre $y_i$.

-   Para $p$ variables explicativas, el modelo puede expresarse como:

**Componente sistemático:**

$$E[Y | X_1 = x_{1i}, ..., X_p = x_{pi}] = E[y_i] =  \mu_i = \beta_0 + \beta_1x_{1i} + ... + \beta_px_{pi}$$

**Componente aleatoria:**

$$y_i \sim N(\beta_0 + \beta_1x_{1i} + ... + \beta_px_{pi}, I\sigma^2)$$

$$\epsilon_i \sim N(0, \sigma^2) $$

## Regresión Lineal en gráficos

::: panel-tabset
### RLS

::: columns
::: {.column width="40%"}
-   La ecuación de la RLS representa una línea recta.
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-linea.png")
```

:::
:::

### RLM con 2 X

::: columns
::: {.column width="40%"}
-   La ecuación de la RLM con dos variables explicativas ya no representa una línea recta, sino un plano recto.
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 80%
knitr::include_graphics("img/regresion-plano.png")
```
:::
:::

### RLM con 3 o más X

-   Genera un hiperplano recto.

-   No podemos imaginarnos una imagen de esto, pero sí podemos analizarlo a nivel estadístico.

    -   Algebra lineal proporciona herramientas para lidiar con esto usando matrices.
:::

# Regresión Lineal Múltiple en R 

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(1000, 15, 1)
y <- -10 * x + 1.3 * z + rnorm(100, 0, 2)

datos2 <- data.frame(
  x1_tto = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2_ttonum = x, 
  x3_peso_inicial = z, 
  y_peso_final = y)
```

## lm() para RLM paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='50%'}

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto, 
          data = datos2)
summary(mod)
```

- El modelo RLS solo incluye una covariable.

:::

::: {.column width='50%'}

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto, 
          data = datos2)
summary(mod)
```

:::

::::

## lm() para RLM paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='50%'}

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, 
          data = datos2)
summary(mod)
```

- El modelo RLS solo incluye una covariable.

- El modelo de RLM incluye 2 o más covariables.

    - Estas se agregan con un símbolo `+`
    
    - Notar que no se reportan intervalos de confianza al 95%. 

:::

::: {.column width='50%'}

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, 
          data = datos2)
summary(mod)
```

:::

::::

## {broom} paso a paso 

- El paquete [{broom}]{.verde-h3} tiene funciones que facilitan obtener varios estadísticos de interés de los modelos de regresión.

- La función [tidy()]{.verde-h3} permite obtener intervalos de confianza y otras medidas de interés.


## {broom} paso a paso {auto-animate=true}

- El paquete [{broom}]{.verde-h3} tiene funciones que facilitan obtener varios estadísticos de interés de los modelos de regresión.

- La función [tidy()]{.verde-h3} permite obtener intervalos de confianza y otras medidas de interés.

- Además, retorna un `tibble()` que puede manipularse y luego embeberse en una tabla.

- Primero se carga el paquete:

```{r}
#| eval: false
library(broom)
```

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy()
```

- La función [tidy()]{.verde-h3} genera un resultado en formato `tibble()` que puede ser manipulado, exportado a excel, y convertido a tabla.

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy()
```
:::

::::

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE)
```

- Con el argumento `conf.int = TRUE` mostramos también los intervalos de confianza.

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE)
```
:::

::::

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  gt()
```

- Podemos convertir en tabla `gt()` para mejorar visualización

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  gt() %>%  
  tab_options(table.font.size = px(18)) 
```
:::

::::


## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  rio::export("tabla_regresion.xlsx")
```

- Otra opción es decargar los resultados en un excel, con la función [export()]{.verde-h3} del paquete [{rio}]{.verde-h3}

:::

::: {.column width='60%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  rio::export("tabla_regresion.xlsx")
```

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/tabla_reg.png")
```


:::

::::

## {broom} paso a paso {auto-animate=true}


```{r}
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate = round(estimate, 2), 
         conf.low = round(conf.low, 2), 
         conf.high = round(conf.high, 2), 
         p.value2 = case_when(
           p.value < 0.001 ~ "<0.001", 
           p.value >= 0.001 ~ as.character(round(p.value, 3))
         )) %>% 
  select(term, estimate, conf.low, conf.high, p.value2) %>% 
  gt()
```

- También podemos manipular la tabla para personalizarla usando "verbos" del paquete [{dplyr}]{.verde-h3}.

## {broom} paso a paso {auto-animate=true}

```{r}
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate = round(estimate, 2), 
         conf.low = round(conf.low, 2), 
         conf.high = round(conf.high, 2), 
         p.value2 = case_when(
           p.value < 0.001 ~ "<0.001", 
           p.value >= 0.001 ~ paste("= ", round(p.value, 3))
         )) %>% 
  mutate(
    `Coeficiente (IC95%), p valor` = 
      glue("{estimate} (IC95% {conf.low} a {conf.high}), p {p.value2}"), 
    Variables = c("Intercepto", "Tratamiento nuevo vs. Placebo", "Peso inicial (kg)")
  ) %>% 
  select(Variables, `Coeficiente (IC95%), p valor`) %>% 
  gt()
```

- Incluso más personalización de lo que imaginan...

## En resumen

::: {.panel-tabset}

### Modelo estimado

```{r}
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)
summary(mod)
```
:::{.callout-note collapse=false appearance='default' icon=false}

##

$$y\_pesofinal = -0.94719 -10.25530*x1ttoTratamientoNuevo + 1.3875*x3\_pesoinicial + \epsilon_i$$

$$\epsilon_i \sim Normal(0, 2.073^2)$$
:::

### Modelo para interpretación

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)

mod %>% 
  tidy(conf.int = TRUE) %>% 
  gt() %>% 
  tab_options(table.font.size = px(18)) 
```

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)

mod %>% 
  tidy(conf.int = TRUE) %>% 
  gt() 
```

### Interpretación 

-   $\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg y cuando el tratamiento es placebo. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor.

-   $\beta_2$ o coeficiente de regresión de `x1_ttoTratamiento Nuevo`: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.26 kg menor que el de quienes recibieron placebo, luego de ajustar por peso inicial (Dif. medias = -10.26; IC95% -10.51 a -9.99; p \< 0.001).

-   $\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.39 kg, luego de ajustar por tatamiento recibido (IC95% 1.26 a 1.52; p \< 0.001).


:::

# Evaluación de Supuestos 

## Errores y residuos

-   Los `errores` ($\epsilon_i$) son medidas de la población a la que no tenemos acceso.

    -   Sin embargo, varios supuestos de la regresión involucran a los errores inaccesibles por el investigador.

-   Los `residuos` ($e_i$) son el análogo a los `errores` pero obtenidos de la `muestra observada`.

-   Podemos usar los `residuos` para `evaluar` algunos `supuestos` sobre los `errores`.

## Residuos gráficamente

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/recta-residuo.png")
```


## Supuestos de la regresión lineal normal

**Supuestos estadísticos del modelo** 

- Linealidad

-   Independencia de observaciones

-   Homocedasticidad de los errores $\epsilon_i$

-   Normalidad de los errores $\epsilon_i$ o de $y_i$.

-   No problemas con la regresión:

    -   Puntos influyentes.
    -   (Multi) colinealidad: Solo cuando es un problema, no siempre lo es.

## Supuestos adicionales que suelen acompañar a la regresión lineal normal

::: {.panel-tabset}

### Generalizar a población finita conocida

**Supuestos si queremos generalizar a una población finita bien definida**

-   La muestra es representativa de la población.

    -   Ideal para alcanzar esto es mediante muestreo probabilístico: representatividad estadística.

-   Cuando no lo tenemos, solo podemos generalizar a una población que sabemos que existe pero no podemos definir. ¿Qué tan relevante puede ser esto?

    -   Otros consideran (¿ingenuamente?) que, bajo ciertas condiciones, se puede alcanar una representativadad teórica.

### Inferencia causal

-   Hay asignación aleatoria

    -   Ideal para alcanzar esto es mediante experimento aleatorizado.

-   Cuando no lo tenemos, tenemos que poder asumir (¿ingenuamente?) que se puede emular la asignación aleatoria de alguna manera:

    -   El ajuste de regresión por confusores es una manera de pensar en esto.

:::


## Algunas notas sobre los errores y residuos para evaluar supuestos

-   En realidad, los supuestos de los modelos lineales son sobre el comportamiento probabilístico de $y_i$.

-   Sin embargo, la idea de la existencia de los `errores` y de sus valores observados en la muestra, `residuos` resulta útil para evaluar supuestos.

    -   Permiten reducir un problema de muchas dimensiones a solo 1 o 2 dimensiones.

    -   Son como las placas radiográficas para el diagnóstico de los modelos.

## Algunas notas sobre los errores y residuos para evaluar supuestos

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100$
knitr::include_graphics("img/residuos-placa.png")
```

## ¿Cómo evaluar los supuestos de la regresión lineal? {.scrollable}

-   Se usan los residuos para explorar el comportamiento de los $y_i$ o los errores $\epsilon$.

-   Preferiblemente usar gráficos de residuos.

    -   Pruebas de hipótesis que usan residuos tienen los mismos problemas que discutimos en clases anteriores.

    -   Podríamos usarlas para complementar análisis cuando los tamaños de muestra no son ni muy pequeños ni muy grandes.

-   La función `check_model` del paquete `{performance}` genera un panel de gráficos muy útil para evalur estos supuestos.

-   Podemos complentar el análisis de supuestos con funciones del paquete `{car}`.

::: panel-tabset
### Panel general

```{r}
#| fig-width: 10
#| fig-height: 15
library(performance)
check_model(mod)
```

### Lin. det.

-   Podemos usar gráficos de residuos parciales + Componente:

```{r}
library(car)
crPlots(mod)
```

-   También podemos usar gráficos de variable agregada

```{r}
avPlots(mod)
```

### Homo. det.

-   Se puede evaluar si la homocedasticidad es consistente según cada variable predictora.

-   Si no lo es, se puede optar por modelar esta heterogeneidad de varianzas.

-   Se sugiere usar `residuos estudentizados`.

```{r}
residualPlots(mod, type = "rstudent")
```

### P. inf. det.

-   En el caso de modelos explicativos, importa determinar si hay un impacto en los coeficientes de regresion.

-   Los `dfbetas` pueden ser útiles para evaluar esto:

```{r}
dfbetasPlots(model = mod, id.n = 5)
```

-   Otras medidas también pueden evaluarse:

```{r}
#| fig-width: 10
#| fig-height: 15
influenceIndexPlot(model = mod, id.n = 5)
```
:::

## ¿Cómo flexibilizar supuestos? {.scrollable}

::: panel-tabset
### No linealidad

-   El supuesto de linealidad es sobre los coeficientes de regresión $\beta$, no sobre las covariables.

-   Las variables X deben estar en una forma apropiada para que el supuesto se cumpla.

-   Es bien difícil que exista linealidad en la realida, pero puede ocurrir en raras y excepcionales ocasiones.

    -   Sobre todo cuando la variable está acotada en valores donde la linealidad es plausible.

-   Se sugiere asumir no linealidad y pre-planear un modelamiento no lineal.

-   Entre los métodos que pueden usarse, tenemos:

    -   `Splines`: Bastante usado y sugerido en bioestadística. Útil para ajustar por variables continuas.

    -   `Modelamiento Multivariablede polinomios fraccionales`. También usado y recomendado en literatura biomédica. Útil para modelar forma como objetivo principal.

    -   `Polinomios`. Menos flexible, puede ser útil si se conoce bien la relación o se busca mejorar ajuste.

    -   `Modelos aditivos generalizados`. Útil si se buscar modelar la relación. Complejos y requieren muchos datos.

-   Veamos un ejemplo de modelamiento continuo con `splines`:

::: callout-note
## Evite categorizar la variable continua

-   Categorizar es muy malo: se pierde información y se corre el riesgo de sesgar resultados.

-   Si se quiere ajustar por variables continuas, use Splines o Polinomios fraccionales. No requiere interpretar sus resultados, pero si ajsutar bien!

-   Si se quiere evaluar la relación de la variable continua, planee un método estadístico para modelar la forma sin asumir linealidad.

    -   Presuponga que la relación no es lineal.

    -   Modelo y responda su pregunta. Si la relación es lineal, el modelo más complejo revelerá una línea recta.
:::

### Heterocedasticidad

-   No homogeneidad de varianzas

-   Podemos usar una estimación robusta de la varianza.

-   Los paquetes `{sanwich}` y `{lmtest}` proporcionan funciones útiles para esto.

-   Es bien difícil de creer que existe homogeneidad de varianzas en la vida real (salvo muy raras y excepcionales ocasiones).

    -   Se sugiere planear el proyecto asumiendo que no hay homocedasticidad y usar inferencia robusta de manera pre-planeada.

```{r}
library(lmtest)
library(sandwich)
coeftest(mod, vcov = vcovHC) %>% 
  tidy(conf.int = TRUE)
```

### No normalidad

-   Si distribución es normal (cosa que no podemos saber con certeza), podemos dejar de preocuparnos por este supuesto.

-   Si se cumple TLC, podemos dejar de preocuparnos por este supuesto.

-   Si no se cumple TLC o hay dudas razonables, podemos optar por alguna de las siguientes alternativas:

    -   Transformar Y para normalizar (p. ej., logaritmo)
    -   Usar varianza robusta
    -   Estimar varianza con bootstrapping u otro método de remuestreo.
:::

## 

::: r-fit-text
<center>¡Gracias!</center>

<center>¿Preguntas?</center>
:::

## 

\

\

\

::: r-fit-text
<center>

{{< fa brands twitter >}}

{{< fa brands github >}} https://github.com/psotob91

{{< fa inbox >}} percys1991@gmail.com

</center>
:::
