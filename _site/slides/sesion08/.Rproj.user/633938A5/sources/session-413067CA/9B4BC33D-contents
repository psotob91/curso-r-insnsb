---
format: 
  revealjs: 
    self-contained: true
    theme: [default, theme/theme.scss]
    footer: "R Aplicado a los Proyectos de Investigación - Sesión 8"
    logo: img/icon-512-insnsb.jpg
    transition: convex
    background-transition: zoom
    incremental: false
    slide-number: c/t
    preview-links: true
    # width: 1920
    # height: 1080
    height: 900
    width: 1600
    # parallax-background-image: img/bg-ietsi-slide-first.png
    # parallax-background-size: "1920px 1080px"
    # chalkboard: true
    code-block-background: true
    code-block-border-left: "#31BAE9"
    highlight-style: ayu-dark
    echo: true
    multiplex: true
    touch: true
    auto-stretch: true
    link-external-icon: true
    link-external-newwindow: true
    self-contained-math: true
    
from: markdown+emoji
execute:
  echo: true
filters:
  - reveal-auto-agenda
  - grouped-tabsets
auto-agenda:
  bullets: numbered
  heading: Agenda
---

\

\

<h1>Sesión 8</h1>

<h2>[Curso: R Aplicado a los Proyectos de Investigación]{.plo}</h2>

<hr>

<h3>[Percy Soto-Becerra, M.D., M.Sc(c)]{.negro}</h3>

<h4>[InkaStats Data Science Solutions \| Medical Branch]{.negro}</h4>

<h4>[2022-10-19]{.negro}</h4>

`r fontawesome::fa("github", "black")`   <https://github.com/psotob91>

![](img/social-image-f22.png){.absolute top="390" left="950" width="600"}

```{r}
#| echo: false
#| output: false

# Removing all objects including loaded libraries
rm(list = ls(all = TRUE))
gc()

# Installing and loading packages
if (!require("pacman")) {
  install.packages("pacman")
}

pacman::p_unload("all") # Unloading all package except base

pacman::p_load(tidyverse, 
               tibble, 
               labelled, 
               pander, 
               gt, 
               kableExtra, 
               DT, 
               haven, 
               skimr, 
               Hmisc, 
               janitor, 
               rio, 
               gtsummary, 
               gt, 
               flextable, 
               kableExtra, 
               readxl, 
               rstatix, 
               medicaldata, 
               ggpubr, 
               car, 
               performance,
               see, 
               lmtest, 
               sandwich, 
               splines2, 
               plotly, 
               glue) # Loading packages

md_visit <- import("rwm5yr.dta") %>% 
  characterize()

```

# Introducción al modelado de regresión

## Análisis de regresión

> Conjunto de técnicas estadística para estimar la relación entre variables.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion1.png")
```

## Modelos de regresión multivariable

> Los modelos de regresión multivariable modelan una sola variable dependiente en función de una o más variables independientes.

- El desenlace define el tipo de regresión multivariable.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion2.png")
```

## ¿Para qué usamos los modelos de regresión?

-   Según `STRATOS` podemos usar regresión para 3 propósitos diferentes:

    -   <FONT size='6'>Descripción\*</FONT>

    -   <FONT size='6'>Predicción</FONT>

    -   <FONT size='6'>Explicación</FONT>

## Propósitos del modelamiento

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/modelos1.png")
```

::: aside
<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>
:::

## Propósitos del modelamiento (cont.)

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/modelos2.png")
```

::: aside
<br> <FONT size='4'>Clasificación inspirado en: Miguel A. Hernán, John Hsu & Brian Healy (2019) A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks, CHANCE, 32:1, 42-49, DOI: 10.1080/09332480.2019.1579578</FONT>
:::

## ¿Para qué usamos los modelos de regresión? (cont.)

-   Este curso se centrará solamente en algunas aplicaciones.

-   No abordaremos modelos de regresión para desarrollar modelos o reglas de predicción clínica.

-   Tampoco para métodos de inferencia causal robusta.

::: panel-tabset
### Descripción

-   Evaluación de la magnitud de desigualdades, magnitud de brechas, etc.
-   "Factores asociados..:" No necesariamente importa que los factores sean causales.

### Explicación

-   "Efecto / Efectividad / Impacto": Busca estimar efectos causales.
-   Explorar potenciales factores causales... (puede clasificarse dentro de descripción)

### Predicción

-   Factores pronóstico o predictores de...": Identifican predictores de interés que luego alimenten mdelos predictivos.
-   Modelos de predicción: Predicción para diagnóstico y pronóstico.
:::

# Modelo de Regresión Lineal Simple

## Regresión Lineal

> Método estadístico que modela la `relación` entre una `variable continua (dependiente)` y otras `variables (independientes)`.

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-lineal.png")
```

## Relación entre dos variables

::: columns
::: {.column width="30%"}
-   $Y$ es `variable resultado` (*outcome*), respuesta o dependiente.

-   $X$ es una `variable explicativa`, predictora o regresora.

-   En la figura, a mayor valor de $X$, mayor valor de $Y$.

```{r}
#| echo: false
set.seed(123)
x = rnorm(500, 0, 1)
y = 4 * x + rnorm(50, 0, 2)

datos <- data.frame(
  x = x, 
  y = y)
```
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## ¿Cómo podemos resumir la relación entre ambas variables?

::: columns
::: {.column width="30%"}
-   Podemos tratar de dibujar una `línea recta` que `resuma` la relación.

-   Existen `infinitas rectas posibles` que podríamos trazar: ¿Cuál elegir?
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_abline(aes(x = x, y = y), intercept = -1, slope = 1, colour = "red") + 
  geom_abline(aes(x = x, y = y), intercept = 0.07, slope = 4.4 , colour = "green") + 
    geom_abline(aes(x = x, y = y), intercept = 0.07, slope = 3.9 , colour = "orange") + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## ¿Cómo podemos resumir la relación entre ambas variables? (cont.)

::: columns
::: {.column width="30%"}
-   Una opción sería elegir una `recta` que pase por el `valor más representativo` del $y_i$ en cada valor fijo de $x_1$.
    -   Una `recta` que `conecte` los `promedios condicionados` en $x_1$
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
 
datos %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) + 
  labs(x = "X", y = "Y") + 
  theme_bw()
```
:::
:::

## Anatomía de la RLS {.scrollable}

-   Entonces, el modelo de `regresión lineal simple` se puede expresar de la siguiente manera:


$$y_i = \underbrace{\beta_0 + \beta_1x_{1i}}_{\text{componente}  \\ \text{sistemático}} + \underbrace{\epsilon_i}_{\text{componente} \\ \text{aleatorio}}$$

- El `componente sistemático` describe  la media de $y_i$ en cada valor fijo de $x_{1i}$: `Media condicionada de y en x`.

    - Pero el promedio no existe, los que existen son los individuos.

- El `componente aleatorio` describe la variación de los individuos alrededor de cada media condiciona de y:

    - Se asume cierta distribución conocida.

## Componente sistemático {.scrollable}

-    Formalmente hablando, para cada `observación` $i$ en la población, podemos `relacionar` el `valor esperado` (media) $E[y_i]$ de $y_i$ (también llamado $\mu_i$) con la `variable explicativa` $x_{1i}$ mediante la siguiente `ecuación lineal`:

$$E[Y | X_1 = x_{1i}] = E[y_i] =  \mu_i = \beta_0 + \beta_1x_{1i}$$


-   Donde:
    -   $y_i$ son realizaciones de `variables aleatorias` independientes e idénticamente distribuidas (`i.i.d`)
    -   $x_1$ es una variable cuyas valores son fijos y conocidos: $x_1i$:
    -   $\beta_0$ y $\beta_1$ son `parámetros desconocidos` de una superpoblación infinita.

## Algunasn notas sobre el componente sistemático {.scrollable}

:::{.callout-note collapse=false appearance='default' icon=false}
## $x_1$ es fijo
-   Se asume se miden sin error.
-   No importa su distribución.
:::

:::{.callout-note collapse=false appearance='default' icon=false}
## $\beta_0$ y $\beta_1$
-   Llamados `coeficientes de regresión` y son una `medida de asociación`.
-   Es lo que `queremos estimar` con los datos de la muestra!
:::
    
:::{.callout-warning collapse=false appearance='default' icon=true}
## Advertencia
-   Notar que el `componente sistemático` solo `relaciona` el `promedio condicionado` de $y_i$ con las `variables explicativas`, NO con los valores individuales.
-   Esta es una manera de obtener una medida que resuma las relaciones individuales en una sola medida.
:::
    

## Componente aleatorio {.scrollable}

-   Para poder relacionar completamente los valores individuales con la ecuación de regersión se agrega un término de error $\epsilon$, el cual se obtiene de restar el valor observado $y_i$ con el valor esperado de este ($\mu_i$):

$$\epsilon_i = y_i - \mu_i$$

-   El problema es que el término de error $\epsilon_i$ no puede predecirse ni estimarse con los datos, se considera que es el `componente no explicado` por la variable independiente.

    -   Para lidiar con este, se asume que su comportamiento puede predecirse a nivel probabilístico: Se asume una distribución de este.
    -   El error $\epsilon_i$ hereda la distribución de probabilidad de $y_i$.

## Componente aleatorio (cont.) {.scrollable}

-   Por lo tanto, el valor individual de cada $y_i$ puede ser denotado por la siguiente expresión:

$$y_i = \beta_0 + \beta_1x_{1i} + \epsilon_i$$

-   Para hacer inferencia estadística, a menudo se asume lo siguiente:

$$y_i \sim N(\beta_0 + \beta_1x_{1i}, \sigma^2)$$

$$\epsilon_i \sim N(0, \sigma^2) $$ 

## En resumen

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-normal.png")
```

## Estimación de ecuación de regresión

-   En la práctica no conocemos los valores de los parámetros, así que los estimamos de nuestros datos.

![](img/regresion-parametro-estim.png)

## ¿Cómo estimamos la ecuación lineal que mejor ajusta a los datos observados?

-   Usamos `métodos numéricos`:

    -   `Método de Mínimos Cuadrados Ordinarios (MCO)`

    -   Método de `Máxima Verosimilitud (MV)`

-   MCO y MV son equivalentes para el caso de la regresión lineal normal.

- El `estimador MCO` es `insesgado`, no importa la distribución de $y_i$ o $\epsilon_i$.

- El estimador MCO tiene `mínima varianza` si y solo si:

    - Hay `independencia de observaciones`.
    - Hay `normalidad`.

## Algunas notas sobre normalidad

-   No es necesario que $\epsilon_i$ o  sigan una distribución normal para que los coeficientes de regresión $\beta$ puedan estimarse de manera puntual.

-   Sin embargo, para estimar el `valor p` o los `intervalos de confianza` mediante `inferencia clásica` sí se necesita asumir una distribución conocida. 

    - El modelo de regresión lineal normal asume normalidad de $y_i$ y $\epsilon_i$.

    -   Sin embargo, el modelo es robusto a desviaciones leves/moderadas de la normalidad cuando se cumple el TLC (número de observaciones grande).

-   Otros enfoques para inferencia flexibilizan este supuesto: 

    - Bootstrap, varianza robusta, modelo lineal generalizado que asume otras distribuciones, etc.


## Regresión Lineal Simple sobre variable explicativa categórica


:::: {.columns}

::: {.column width='40%'}
-   Las `variables categóricas` no son continuas, en cambio son discretas y asumen solo unos cuantos valores.

-   ¿Cómo estimar una medida de asociación cuando la variable explicativa es categórica?

- Veamos el caso binario.

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
y <- 4 * x + rnorm(50, 0, 2)

datos <- data.frame(
  x1 = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2 = x, 
  y = y)
```
:::

::: {.column width='60%'}

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
datos %>% 
  ggplot(aes(x = x1, y = y)) + 
  geom_point() + 
  theme_bw()
```

:::

::::


## Regresión Lineal Simple sobre variable explicativa categórica (cont.)

:::: {.columns}

::: {.column width='40%'}
-   Si la variable es `binaria`, asignamos a una categoría el `valor de 1` y a otra el `valor de 0`.

    -   Asumiremos que la variable categórica es numérica para los efectos de todo cálculo.

    -   Sin embargo, la interpretación se centrará en la comparación de categorías 0 y 1, nunca se interperará valores intermedios porquen o existen.
:::

::: {.column width='60%'}

```{r}
#| echo: false
datos %>% 
  ggplot(aes(x = x2, y = y)) +   
  geom_smooth(method = "lm", se = FALSE) + 
  geom_point() + 
  theme_bw()
```

:::

::::


# Regresión Lineal Simple en R 

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(50, 15, 1)
y <- 10 * x - 2 * z + rnorm(50, 0, 2)

datos1 <- data.frame(
  x1 = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2 = x, 
  x3 = z, 
  y = y)
```

## lm() paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
lm(y ~ x1, data = datos)
```

-   Se usa la función `lm()` de R base. Sin embargo, la salida de esta no es muy informativa:

    - Solo reportar coefiecientes de regresión (componente sistemático)
:::

::: {.column width='60%'}
```{r}
#| echo: false
lm(y ~ x1, data = datos)
```
:::

::::


## lm() paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
mod <- lm(y ~ x1, data = datos)
```

-   Se usa la función `lm()` de R base. Sin embargo, la salida de esta no es muy informativa:
    
-   El modelo puede guardarse para realizar más operaciones sobre este. Por ejemplo, mejorar la salida.

:::

::: {.column width='60%'}
```{r}
#| echo: false
mod <- lm(y ~ x1, data = datos)
```
:::

::::

## lm() paso a paso {auto-animate=true}


:::: {.columns}

::: {.column width='40%'}
```{r}
#| eval: false
mod <- lm(y ~ x1, data = datos)
summary(mod)
```

-   Se usa la función [lm()]{.verde-h3} de R base. Sin embargo, la salida de esta no es muy informativa:
    
-   El modelo puede guardarse para realizar más operaciones sobre este. Por ejemplo, mejorar la salida.   

- Podemos usar [summary()]{.verde-h3} para ver resultados detallados.


:::

::: {.column width='60%'}
```{r}
#| echo: false
mod <- lm(y ~ x1, data = datos)
summary(mod)
```
:::

::::

## Interpretación de salida de RLS {.scrollable}

::: panel-tabset
### Covariable numérica

-   Usamos la función lm():

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(1000, 15, 1)
y <- -10 * x + 1.3 * z + rnorm(100, 0, 2)

datos2 <- data.frame(
  x1_tto = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2_ttonum = x, 
  x3_peso_inicial = z, 
  y_peso_final = y)
```

```{r}
mod <- lm(y_peso_final ~ x3_peso_inicial, data = datos2)
summary(mod)
```

-   El modelo estimado sería el siguiente:

$$y\_pesofinal = -5.4317 + 1.3447*x3\_pesoinicial + \epsilon_i$$

$$\epsilon_i \sim Normal(0, 5.535^2)$$

-   Usando el paquete `{broom}` y su función `tidy()` podemos obtener también los intervalos de confianza:

```{r}
library(broom)
mod %>% 
  tidy(conf.int = TRUE) 
```

-   Interpretación:

    -   $\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor.

    -   $\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.43 kg (IC95% 1.00 a 1.69; p \< 0.001).

### Covariable categórica

-   Usamos la función lm():

```{r}
mod <- lm(y_peso_final ~ x1_tto, data = datos2)
summary(mod)
```

-   Usando tidy de broom:

```{r}
mod %>% 
  tidy(conf.int = TRUE) 
```

-   Interpretación:

    -   $\beta_0$ (Intercept): A menudo no se interpreta. Es el valor promedio de $y_i$ cuando los valores de $x$ son cero. En este caso, cuando el tratamien es cero (placebo). ¿Esto es posible?, sí es posible pero no es de ayuda para modelos explicativos, por lo que no se interpreta.

    -   $\beta1$ x1Tratamiento Nuevo: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.23 kg menor que el de quienes recibieron placebo (Dif. medias = -10.23; IC95% -10.54 a -9.92; p \< 0.001).
:::

# Regresión Lineal Múltiple

## Regresión Lineal Múltiple {.scrollable}

> El modelo de regresión lineal múltiple generaliza la RLS permitiendo evaluar la relación de varias covariables explicativas $x$ sobre $y_i$.

-   Para $p$ variables explicativas, el modelo puede expresarse como:

**Componente sistemático:**

$$E[Y | X_1 = x_{1i}, ..., X_p = x_{pi}] = E[y_i] =  \mu_i = \beta_0 + \beta_1x_{1i} + ... + \beta_px_{pi}$$

**Componente aleatoria:**

$$y_i \sim N(\beta_0 + \beta_1x_{1i} + ... + \beta_px_{pi}, I\sigma^2)$$

$$\epsilon_i \sim N(0, \sigma^2) $$

## Regresión Lineal en gráficos

::: panel-tabset
### RLS

::: columns
::: {.column width="40%"}
-   La ecuación de la RLS representa una línea recta.
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/regresion-linea.png")
```

:::
:::

### RLM con 2 X

::: columns
::: {.column width="40%"}
-   La ecuación de la RLM con dos variables explicativas ya no representa una línea recta, sino un plano recto.
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| fig-align: center
#| out-width: 80%
knitr::include_graphics("img/regresion-plano.png")
```
:::
:::

### RLM con 3 o más X

-   Genera un hiperplano recto.

-   No podemos imaginarnos una imagen de esto, pero sí podemos analizarlo a nivel estadístico.

    -   Algebra lineal proporciona herramientas para lidiar con esto usando matrices.
:::

# Regresión Lineal Múltiple en R 

```{r}
#| echo: false
set.seed(123)
x <- c(rep(0, 25), rep(1, 25))
z <- rnorm(1000, 15, 1)
y <- -10 * x + 1.3 * z + rnorm(100, 0, 2)

datos2 <- data.frame(
  x1_tto = factor(x, levels = c(0, 1), labels = c("Placebo", "Tratamiento Nuevo")), 
  x2_ttonum = x, 
  x3_peso_inicial = z, 
  y_peso_final = y)
```

## lm() para RLM paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='50%'}

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto, 
          data = datos2)
summary(mod)
```

- El modelo RLS solo incluye una covariable.

:::

::: {.column width='50%'}

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto, 
          data = datos2)
summary(mod)
```

:::

::::

## lm() para RLM paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='50%'}

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, 
          data = datos2)
summary(mod)
```

- El modelo RLS solo incluye una covariable.

- El modelo de RLM incluye 2 o más covariables.

    - Estas se agregan con un símbolo `+`
    
    - Notar que no se reportan intervalos de confianza al 95%. 

:::

::: {.column width='50%'}

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, 
          data = datos2)
summary(mod)
```

:::

::::

## {broom} paso a paso 

- El paquete [{broom}]{.verde-h3} tiene funciones que facilitan obtener varios estadísticos de interés de los modelos de regresión.

- La función [tidy()]{.verde-h3} permite obtener intervalos de confianza y otras medidas de interés.


## {broom} paso a paso {auto-animate=true}

- El paquete [{broom}]{.verde-h3} tiene funciones que facilitan obtener varios estadísticos de interés de los modelos de regresión.

- La función [tidy()]{.verde-h3} permite obtener intervalos de confianza y otras medidas de interés.

- Además, retorna un `tibble()` que puede manipularse y luego embeberse en una tabla.

- Primero se carga el paquete:

```{r}
#| eval: false
library(broom)
```

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy()
```

- La función [tidy()]{.verde-h3} genera un resultado en formato `tibble()` que puede ser manipulado, exportado a excel, y convertido a tabla.

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy()
```
:::

::::

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE)
```

- Con el argumento `conf.int = TRUE` mostramos también los intervalos de confianza.

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE)
```
:::

::::

## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='30%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  gt()
```

- Podemos convertir en tabla `gt()` para mejorar visualización

:::

::: {.column width='70%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  gt() %>%  
  tab_options(table.font.size = px(18)) 
```
:::

::::


## {broom} paso a paso {auto-animate=true}

:::: {.columns}

::: {.column width='40%'}

```{r}
#| eval: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  rio::export("tabla_regresion.xlsx")
```

- Otra opción es decargar los resultados en un excel, con la función [export()]{.verde-h3} del paquete [{rio}]{.verde-h3}

:::

::: {.column width='60%'}
```{r}
#| echo: false
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  rio::export("tabla_regresion.xlsx")
```

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/tabla_reg.png")
```


:::

::::

## {broom} paso a paso {auto-animate=true}


```{r}
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate = round(estimate, 2), 
         conf.low = round(conf.low, 2), 
         conf.high = round(conf.high, 2), 
         p.value2 = case_when(
           p.value < 0.001 ~ "<0.001", 
           p.value >= 0.001 ~ as.character(round(p.value, 3))
         )) %>% 
  select(term, estimate, conf.low, conf.high, p.value2) %>% 
  gt()
```

- También podemos manipular la tabla para personalizarla usando "verbos" del paquete [{dplyr}]{.verde-h3}.

## {broom} paso a paso {auto-animate=true}

```{r}
mod  %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate = round(estimate, 2), 
         conf.low = round(conf.low, 2), 
         conf.high = round(conf.high, 2), 
         p.value2 = case_when(
           p.value < 0.001 ~ "<0.001", 
           p.value >= 0.001 ~ paste("= ", round(p.value, 3))
         )) %>% 
  mutate(
    `Coeficiente (IC95%), p valor` = 
      glue("{estimate} (IC95% {conf.low} a {conf.high}), p {p.value2}"), 
    Variables = c("Intercepto", "Tratamiento nuevo vs. Placebo", "Peso inicial (kg)")
  ) %>% 
  select(Variables, `Coeficiente (IC95%), p valor`) %>% 
  gt()
```

- Incluso más personalización de lo que imaginan...

## En resumen

::: {.panel-tabset}

### Modelo estimado

```{r}
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)
summary(mod)
```
:::{.callout-note collapse=false appearance='default' icon=false}

##

$$y\_pesofinal = -0.94719 -10.25530*x1ttoTratamientoNuevo + 1.3875*x3\_pesoinicial + \epsilon_i$$

$$\epsilon_i \sim Normal(0, 2.073^2)$$
:::

### Modelo para interpretación

```{r}
#| echo: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)

mod %>% 
  tidy(conf.int = TRUE) %>% 
  gt() %>% 
  tab_options(table.font.size = px(18)) 
```

```{r}
#| eval: false
mod <- lm(y_peso_final ~ x1_tto + x3_peso_inicial, data = datos2)

mod %>% 
  tidy(conf.int = TRUE) %>% 
  gt() 
```

### Interpretación 

-   $\beta_0$ o `intercepto`: Este viene a ser el valor promedio de $y$ cuando todos los valores de $x$ son 0. En este caso, cuando el peso inicial es cero kg y cuando el tratamiento es placebo. ¿Esto es posible?, por tal motivo, no se suele interpretar este valor.

-   $\beta_2$ o coeficiente de regresión de `x1_ttoTratamiento Nuevo`: El promedio de peso final en quienes recibieron el tratamiento nuevo fue 10.26 kg menor que el de quienes recibieron placebo, luego de ajustar por peso inicial (Dif. medias = -10.26; IC95% -10.51 a -9.99; p \< 0.001).

-   $\beta_1$ o coeficiente de regresión de `x3_peso_inicial`: Por `cada 1 kg adicional` de peso inicial, el `valor promedio` del peso final aumenta 1.39 kg, luego de ajustar por tatamiento recibido (IC95% 1.26 a 1.52; p \< 0.001).


:::

# Evaluación de Supuestos 

## Errores y residuos

-   Los `errores` ($\epsilon_i$) son medidas de la población a la que no tenemos acceso.

    -   Sin embargo, varios supuestos de la regresión involucran a los errores inaccesibles por el investigador.

-   Los `residuos` ($e_i$) son el análogo a los `errores` pero obtenidos de la `muestra observada`.

-   Podemos usar los `residuos` para `evaluar` algunos `supuestos` sobre los `errores`.

## Residuos gráficamente

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100%
knitr::include_graphics("img/recta-residuo.png")
```


## Supuestos de la regresión lineal normal

**Supuestos estadísticos del modelo** 

- Linealidad

-   Independencia de observaciones

-   Homocedasticidad de los errores $\epsilon_i$

-   Normalidad de los errores $\epsilon_i$ o de $y_i$.

-   No problemas con la regresión:

    -   Puntos influyentes.
    -   (Multi) colinealidad: Solo cuando es un problema, no siempre lo es.

## Supuestos adicionales que suelen acompañar a la regresión lineal normal

::: {.panel-tabset}

### Generalizar a población finita conocida

**Supuestos si queremos generalizar a una población finita bien definida**

-   La muestra es representativa de la población.

    -   Ideal para alcanzar esto es mediante muestreo probabilístico: representatividad estadística.

-   Cuando no lo tenemos, solo podemos generalizar a una población que sabemos que existe pero no podemos definir. ¿Qué tan relevante puede ser esto?

    -   Otros consideran (¿ingenuamente?) que, bajo ciertas condiciones, se puede alcanar una representativadad teórica.

### Inferencia causal

-   Hay asignación aleatoria

    -   Ideal para alcanzar esto es mediante experimento aleatorizado.

-   Cuando no lo tenemos, tenemos que poder asumir (¿ingenuamente?) que se puede emular la asignación aleatoria de alguna manera:

    -   El ajuste de regresión por confusores es una manera de pensar en esto.

:::


## Algunas notas sobre los errores y residuos para evaluar supuestos

-   En realidad, los supuestos de los modelos lineales son sobre el comportamiento probabilístico de $y_i$.

-   Sin embargo, la idea de la existencia de los `errores` y de sus valores observados en la muestra, `residuos` resulta útil para evaluar supuestos.

    -   Permiten reducir un problema de muchas dimensiones a solo 1 o 2 dimensiones.

    -   Son como las placas radiográficas para el diagnóstico de los modelos.

## Algunas notas sobre los errores y residuos para evaluar supuestos

```{r}
#| echo: false
#| fig-align: center
#| out-width: 100$
knitr::include_graphics("img/residuos-placa.png")
```

## ¿Cómo evaluar los supuestos de la regresión lineal? {.scrollable}

-   Se usan los residuos para explorar el comportamiento de los $y_i$ o los errores $\epsilon$.

-   Preferiblemente usar gráficos de residuos.

    -   Pruebas de hipótesis que usan residuos tienen los mismos problemas que discutimos en clases anteriores.

    -   Podríamos usarlas para complementar análisis cuando los tamaños de muestra no son ni muy pequeños ni muy grandes.

-   La función `check_model` del paquete `{performance}` genera un panel de gráficos muy útil para evalur estos supuestos.

-   Podemos complentar el análisis de supuestos con funciones del paquete `{car}`.

::: panel-tabset
### Panel general

```{r}
#| fig-width: 10
#| fig-height: 15
library(performance)
check_model(mod)
```

### Lin. det.

-   Podemos usar gráficos de residuos parciales + Componente:

```{r}
library(car)
crPlots(mod)
```

-   También podemos usar gráficos de variable agregada

```{r}
avPlots(mod)
```

### Homo. det.

-   Se puede evaluar si la homocedasticidad es consistente según cada variable predictora.

-   Si no lo es, se puede optar por modelar esta heterogeneidad de varianzas.

-   Se sugiere usar `residuos estudentizados`.

```{r}
residualPlots(mod, type = "rstudent")
```

### P. inf. det.

-   En el caso de modelos explicativos, importa determinar si hay un impacto en los coeficientes de regresion.

-   Los `dfbetas` pueden ser útiles para evaluar esto:

```{r}
dfbetasPlots(model = mod, id.n = 5)
```

-   Otras medidas también pueden evaluarse:

```{r}
#| fig-width: 10
#| fig-height: 15
influenceIndexPlot(model = mod, id.n = 5)
```
:::

## ¿Cómo flexibilizar supuestos? {.scrollable}

::: panel-tabset
### No linealidad

-   El supuesto de linealidad es sobre los coeficientes de regresión $\beta$, no sobre las covariables.

-   Las variables X deben estar en una forma apropiada para que el supuesto se cumpla.

-   Es bien difícil que exista linealidad en la realida, pero puede ocurrir en raras y excepcionales ocasiones.

    -   Sobre todo cuando la variable está acotada en valores donde la linealidad es plausible.

-   Se sugiere asumir no linealidad y pre-planear un modelamiento no lineal.

-   Entre los métodos que pueden usarse, tenemos:

    -   `Splines`: Bastante usado y sugerido en bioestadística. Útil para ajustar por variables continuas.

    -   `Modelamiento Multivariablede polinomios fraccionales`. También usado y recomendado en literatura biomédica. Útil para modelar forma como objetivo principal.

    -   `Polinomios`. Menos flexible, puede ser útil si se conoce bien la relación o se busca mejorar ajuste.

    -   `Modelos aditivos generalizados`. Útil si se buscar modelar la relación. Complejos y requieren muchos datos.

-   Veamos un ejemplo de modelamiento continuo con `splines`:

::: callout-note
## Evite categorizar la variable continua

-   Categorizar es muy malo: se pierde información y se corre el riesgo de sesgar resultados.

-   Si se quiere ajustar por variables continuas, use Splines o Polinomios fraccionales. No requiere interpretar sus resultados, pero si ajsutar bien!

-   Si se quiere evaluar la relación de la variable continua, planee un método estadístico para modelar la forma sin asumir linealidad.

    -   Presuponga que la relación no es lineal.

    -   Modelo y responda su pregunta. Si la relación es lineal, el modelo más complejo revelerá una línea recta.
:::

### Heterocedasticidad

-   No homogeneidad de varianzas

-   Podemos usar una estimación robusta de la varianza.

-   Los paquetes `{sanwich}` y `{lmtest}` proporcionan funciones útiles para esto.

-   Es bien difícil de creer que existe homogeneidad de varianzas en la vida real (salvo muy raras y excepcionales ocasiones).

    -   Se sugiere planear el proyecto asumiendo que no hay homocedasticidad y usar inferencia robusta de manera pre-planeada.

```{r}
library(lmtest)
library(sandwich)
coeftest(mod, vcov = vcovHC) %>% 
  tidy(conf.int = TRUE)
```

### No normalidad

-   Si distribución es normal (cosa que no podemos saber con certeza), podemos dejar de preocuparnos por este supuesto.

-   Si se cumple TLC, podemos dejar de preocuparnos por este supuesto.

-   Si no se cumple TLC o hay dudas razonables, podemos optar por alguna de las siguientes alternativas:

    -   Transformar Y para normalizar (p. ej., logaritmo)
    -   Usar varianza robusta
    -   Estimar varianza con bootstrapping u otro método de remuestreo.
:::

# El Modelo Lineal Generalizado

## Modelo Lineal Generalizado

> Modelo lineal que permite modelar desenlaces de varios tipos de distribuciones.

-   Generaliza el modelo de regresión lineal.

-   Permite que $Y_i$ siga otras distribuciones.

    - Pertenecientes a la familia de distribución exponencial. 
    

## Modelo Lineal Generalizado: Anatomía

**Componente sistemático:**

$$
g(E(Y|x_{1i}, ..., x_{pi})) = g(E(Y_i)) = \eta_i = \beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip}
$$

-   $g()$ es la `función de enlace`.

-   $\eta_i$ es el `predictor linear`.

- $E(Y|x_{1i}, ..., x_{pi}) = \mu_i$ 

**Componente aleatorio:**

$$
Y_i \sim Distribucion~de~la~Familia~Exponencial
$$

## Familia exponencial {.scrollable}

| Variable respuesta    |       Distribución de FE       | Función de enlace canónica $g()$ | Otras funciones de enlace comunes |
|:----------------|:---------------:|:----------------:|:-----------------:|
| **Binaria**           | Bernoulli (Binomial con n = 1) |            $logit()$             |              $log()$              |
| **Conteo**            |     Binomial (con n \> 1)      |            $logit()$             |              $log()$              |
|                       |            Poisson             |             $log()$              |                                   |
|                       |       Binomial negativo        |          $log(\mu + k)$          |              $log()$              |
| **Continua positiva** |             Gamma              |         $\frac{1}{\mu}$          |                                   |
|                       |        Gausiana inversa        |                                  |                                   |


## Estimación de GLM

- Hace uso de `estimación de máxima verosimilitud` (MV).

- Salvo el caso normal (donde MV = MCO), `no existe solución cerrada` para obtener los estimadores de MV.
    
    - Hay que hacer uso de `métodos numéricos`: Fisher Scoring, Newton Raphson, etc.

- No siempre la función de verosimilitud tiene un máximo.

    - Solo cuando se usa la función de enlace canónica.
    
    - Caso contrario, puede no tener solución única y hay problemas de convergencia.

# La regresión de Poisson

## El modelo de regresión de Poisson {.scrollable}

$$y_i \sim Poisson(\beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip})$$

:::: {.columns}

::: {.column width='50%'}

-   **Componente sistemático:**

$$log(E(y_i)) = \eta_i$$

:::

::: {.column width='50%'}

-   **Función de enlace:**

$$\eta_i = \beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip}$$
:::

::::

-   **Componente aleatorio:**

$$y_i \sim Poisson(\eta_i)$$


## ¿Por qué usar log? {.scrollable}

- $log()$ es la función de enlace canónica: solución única para MV y no problemas de convergencia por esto.

-   Si usamos la función identidad de la regresión lineal, el modelo quedaría planetado de esta manera:

$$E(y_i) = \beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip}$$


:::{.callout-important collapse=false appearance='default' icon=false}
## 
-   Entonces, el modelo predecirá valores fuera del rango natural de la variable $y_i$:
-   $y_i$ es de conteo (discreto), pero se obtendrían predichos con decimales (continuo).
-   $y_i$ es positivo siempre, pero se podrían ontener predichos negativos.
:::

- El inverso de $log()$, $exp()$ devuelve una `razón de medias`, medida interpretable.

## ¿Por qué no asumir normalidad de $y_i$? {.scrollable}

-   Porque la distribución de $y_i$ no es normal, es una variable de conteo.

-   El principal problema de esto, es que al ser Poisson, la $media = varianza = \lambda$, por lo que a mayor valor de la media, la varianza aumentará.

    - Lo que implica que $y_i$ es una v.a. heterocedástica.

    -   El modelo normal necesita homocedasticidad, caso contrario, tiene que corregirse de alguna manera.

    -   Poisson no necesita esto, su modelo es heterocedastico por naturaleza, lo que hace más eficiente la estimación: 
    
        - Si el modelo es válido, los intervalos de confianza serán más precisos.

## La regresión de Poisson retorna razón de medias

-   La regresión de Poisson permite retornar directamente `razón de medias` (RM).

-   Los coeficientes de regresión $\beta$ del modelo son $log(RM)$, por lo tanto, podemos exponenciarlos para obtener los OR:

$$\beta = log(RM)$$

<center>entonces</center>

$$e^\beta = RM$$

## [glm()]{.verde-h3} paso a paso

```{r}
mod <- glm(docvis ~ female + age, 
           data = md_visit)
summary(mod)
```

- Se especifica la ecuación. 

    - Por defecto, regresión lineal normal

## [glm()]{.verde-h3} paso a paso

```{r}
mod <- glm(docvis ~ female + age, 
           family = poisson, 
           data = md_visit)
summary(mod)
```

- Se indica la familia de distribución de $y_i$.

    - Por defecto, la función de enlace será la canónica.
    
## [glm()]{.verde-h3} paso a paso

```{r}
mod <- glm(docvis ~ female + age, 
           family = poisson(link = "log"), 
           data = md_visit)
summary(mod)
```

- Se indica la familia de distribución de $y_i$.

    - Por defecto, la función de enlace será la canónica.

## [glm()]{.verde-h3} paso a paso

```{r}
mod <- glm(docvis ~ female + age, 
           family = poisson(link = "identity"), 
           data = md_visit)
summary(mod)
```

- Podemos cambiar la función de enlace.
        
        
## [glm()]{.verde-h3} paso a paso

```{r}
mod <- glm(docvis ~ female + age, 
           family = poisson(link = "log"), 
           data = md_visit)
mod %>% 
  tidy() %>% 
  gt()
```

- En el caso de la función de enlace [log]{.verde-h3}, los coeficientes son `log(razón de medias)`, para volverlos interpretables, hay que aplicar antilogaritmo: `exp()`.
    
## [glm()]{.verde-h3} paso a paso

```{r}
mod %>% 
  tidy(exponentiate = TRUE) %>% 
  gt()
```

- La función [tidy()]{.verde-h3} de [{broom}]{.verde-h3} permite hacer esto facilmente: `exponentiate = TRUE`.

## [glm()]{.verde-h3} paso a paso

```{r}
mod %>% 
  tidy(exponentiate = TRUE, conf.int = TRUE) %>% 
  gt()
```

- También podemos agregar intervalos de confianza.

## Casos aplicado {.scrollable}

-   Identificar factores asociados a que el niño tenga alergia.

::: panel-tabset
### Caso

-   Factores asociados al número de visitas médicas anuales.

``` r
md_visit <- import("rwm5yr.dta") %>% 
  characterize()
```

-   Especificación del modelo

```{r}
mod <- glm(docvis ~ female + age, 
           family = poisson(link = "log"), 
           data = md_visit)
summary(mod)
```

-   Presentación con intervalos de confianza y exponenciada (OR):

```{r}
mod %>% 
  tidy(conf.int = TRUE, exponentiate = TRUE)
```

### Interpretación

- `female`: El número medio de visitas anuales al médico en mujeres fue 20% veces más el de los hombres (RM = 1.33; IC95% 1.31 a 1.35; p < 0.001)

- `age`: Por cada incremento de la edad en un año, el número medio de visitas anuales al médico se incrementa en 1% (RM = 1.017; IC95% 1.016 a 1.018; p < 0.001). 

### Supuestos

-   Linealidad del $log(y_i)$ respecto a la combinación lineal de predictores.

-   Observaciones son independientes.

-   $Y_i$ sigue distribución de Poisson.

    - Supuesto de equivarianza.

-   No problemas de regresión:

    -   No puntos influyentes

    -   No colinealidad: Solo cuando esta es un problema.

-   Supuestos específicos si se busca generalizar a poblaciones conocidas, hacer inferencias causales o ambas.

### Evaluación de Supuestos

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 15
library(performance)
check_model(mod)
```
:::

# La regresión Binomial Negativa

## El modelo de regresión binomial negativa {.scrollable}

- Si asumimos que $y_i$ tienne un segundo nivel de variabilidad:

$y_i|\lambda_i \sim Poisson(\lambda_i)$ y $\lambda_i \sim Gamma(\mu_i, \psi)$ 

- Entonces, es posible mostrar que $y_i$ sigue una `distribución binomial negativa`.

- Asimismo, el modelo:

$$y_i \sim BN(\beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip}, \psi)$$

:::: {.columns}

::: {.column width='50%'}

-   **Componente sistemático:**

$$log(E(y_i)) = \eta_i$$

:::

::: {.column width='50%'}

-   **Función de enlace:**

$$\eta_i = \beta_0 + \beta_1x_{1i} + ...+ \beta_px_{ip}$$
:::

::::

-   **Componente aleatorio:**

$$y_i \sim BN(\eta_i, \psi)$$


## ¿Por qué usar binomial negativa y no poisson? {.scrollable}

- Porque no siempre la variable $y_i$ seguirá una distribución de Poisson.

- Si sigue una distribución BN, entonces la varianza es mayor a la media (sobredispersion).

    - La estimación del error estándar deberá tener esto en cuenta.
    
    - Caso contrario, sería inválido en dirección anticorservadora.
    
    
## ¿Por qué usar la función de enlace log?

- La función de enlace de la BN no es `log()`, tampoco `identiy()`.

- Sin embargo, se prefiere usar `log()` para obtener resultados interpretables: `razón de medias`.

- Esto conlleva un problema, no siempre hay convergencia:

      - Cuando hay sobredispersión, regresión binomial negativa no siempre es la opción factible.
      
      - Otra opción puede ser usar regresión quasipoisson o un estimador de varianza robusta.

## La regresión BN también retorna razón de medias

-   La regresión BN permite retornar directamente `razón de medias` (RM).

-   Los coeficientes de regresión $\beta$ del modelo son $log(RM)$, por lo tanto, podemos exponenciarlos para obtener las RM:

$$\beta = log(RM)$$

<center>entonces</center>

$$e^\beta = RM$$

## [glm.nb()]{.verde-h3} paso a paso

- Se usa la función [glm.nb()]{.verde-h3} del paquete [MASS]{.verde-h3}:

```{r}
library(MASS)
```

## [glm.nb()]{.verde-h3} paso a paso

```{r}
mod <- glm.nb(docvis ~ female + age, 
           data = md_visit)
summary(mod)
```

- Se especifica la ecuación. 

## [glm.nb()]{.verde-h3} paso a paso

```{r}
mod <- glm.nb(docvis ~ female + age, 
           data = md_visit)
mod %>% 
  tidy() %>% 
  gt()
```

- En el caso de la función de enlace [log]{.verde-h3}, los coeficientes son `log(razón de medias)`, para volverlos interpretables, hay que aplicar antilogaritmo: `exp()`.
    
## [glm.nb()]{.verde-h3} paso a paso

```{r}
mod %>% 
  tidy(exponentiate = TRUE) %>% 
  gt()
```

- La función [tidy()]{.verde-h3} de [{broom}]{.verde-h3} permite hacer esto facilmente: `exponentiate = TRUE`.

## [glm.nb()]{.verde-h3} paso a paso

```{r}
mod %>% 
  tidy(exponentiate = TRUE, conf.int = TRUE) %>% 
  gt()
```

- También podemos agregar intervalos de confianza.

## Casos aplicado {.scrollable}

-   Identificar factores asociados a que el niño tenga alergia.

::: panel-tabset
### Caso

-   Factores asociados al número de visitas médicas anuales.

``` r
md_visit <- import("rwm5yr.dta") %>% 
  characterize()
```

-   Especificación del modelo

```{r}
mod <- glm.nb(docvis ~ female + age, 
           data = md_visit)
summary(mod)
```

-   Presentación con intervalos de confianza y exponenciada (RM):

```{r}
mod %>% 
  tidy(conf.int = TRUE, exponentiate = TRUE)
```

### Interpretación

- `female`: El número medio de visitas anuales al médico en mujeres fue 20% veces más el de los hombres (RM = 1.40; IC95% 1.34 a 1.46; p < 0.001)

- `age`: Por cada incremento de la edad en un año, el número medio de visitas anuales al médico se incrementa en 2.3% (RM = 1.017; IC95% 1.021 a 1.025; p < 0.001). 

### Supuestos

-   Linealidad del $log(y_i)$ respecto a la combinación lineal de predictores.

-   Observaciones son independientes.

-   $Y_i$ sigue distribución de Poisson.

    - Supuesto de equivarianza.

-   No problemas de regresión:

    -   No puntos influyentes

    -   No colinealidad: Solo cuando esta es un problema.

-   Supuestos específicos si se busca generalizar a poblaciones conocidas, hacer inferencias causales o ambas.

### Evaluación de Supuestos

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 15
library(performance)
check_model(mod)
```
:::

# Tablas de regresión reproducibles con {gtsummary}

## Tablas de regresión lineal reproducible {.scrollable}

-   Podemos usar la librería {gtsummary} para esto.

-   Veamos un ejemplo.

```{r}
datos <- import("hb.dta") %>% 
  characterize()
```

## Tablas de regresión lineal reproducible {.scrollable}

-   Podemos reportar la tabla de regreion multivarible de la siguiente manera:

    -   Primero realizamos el modelo:

```{r}
mod <- lm(hb ~ age + sex, data = datos)
mod %>% 
  tidy(conf.int = TRUE)
```

## Tablas de regresión lineal reproducible {.scrollable}

-   Se puede crear una tabla de regresión multivariable con la función `tbl_regression()` de `{gtsummary}`:

```{r}
tabla_multi <- mod %>%  
  tbl_regression()

tabla_multi
```

## Tablas de regresión lineal reproducible {.scrollable}

-   Podemos hacer la tabla de regresiones bivariada con la función `tbl_uvregression()` de `{gtsummary}`:

```{r}
tabla_univ <- datos %>% 
  dplyr::select(age, sex, hb) %>% 
  tbl_uvregression(
    method = lm, 
    y = hb
  ) 

tabla_univ
```

## Tablas de regresión lineal reproducible {.scrollable}

-   Luego, podemos fusionar ambas tablas en una sola con la función `tbl_merge()`:

```{r}
tabla_final <- tbl_merge(list(tabla_univ, tabla_multi), tab_spanner = c("Modelos crudos", "Modelo ajustado")) 

tabla_final
```

## Tablas de regresión lineal reproducible {.scrollable}

-   Podemos exportarlo a MS Word para post-procesamiento y reporte:

```{r}
tabla_final %>% 
  as_flex_table() %>% 
  save_as_docx(path = "Tabla_Final.docx")
```

## 

::: r-fit-text
<center>¡Gracias!</center>

<center>¿Preguntas?</center>
:::

## 

\

\

\

::: r-fit-text
<center>

{{< fa brands twitter >}}

{{< fa brands github >}} https://github.com/psotob91

{{< fa inbox >}} percys1991@gmail.com

</center>
:::
