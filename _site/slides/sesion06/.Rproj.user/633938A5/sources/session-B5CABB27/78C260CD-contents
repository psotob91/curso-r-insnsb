---
title: "<img data-src='images/logo-essalud.png' height='72' width='250'/> <img data-src='images/logo-pueblo.jpg' height='72' width='250'/> <img data-src='images/logo-ietsi.png' height='72' width='250'/> <FONT color='#232429'><br>Sesión 2b</FONT>"
subtitle: "<FONT color='#636363' size='7'>Programa de Formación Científica:<br>Análisis Estadístico 2022</FONT>"
author: "<FONT color='#232429' size='30'>Percy Soto-Becerra</FONT>"
institute: "<FONT color='#232429' size='5'>Instituto de Evaluación de Tecnologías en Salud e Investigación - IETSI, EsSalud<br>@github/psotob</FONT>"
date: "<FONT color='#232429' size='6'>Junio 22, 2022</FONT>"
format: 
  revealjs: 
    theme: default
    footer: "Programa de Formación Científica: Análisis Estadístico 2022 - Sesión 2b"
    logo: images/logo-ietsi.png
    transition: convex
    background-transition: zoom
    incremental: false
    slide-number: true
    preview-links: true
    # parallax-background-image: images/bg-ietsi-slide-first.png
    # parallax-background-size: "1920px 1080px"
    chalkboard: true
    code-block-background: true
    code-block-border-left: "#31BAE9"
    highlight-style: solarized
    echo: true
    multiplex: true
    touch: true
    auto-stretch: true
    link-external-icon: true
    link-external-newwindow: true
---

```{r}
#| echo: false
#| output: false

# Removing all objects including loaded libraries
rm(list = ls(all = TRUE))
gc()

# Installing and loading packages
if (!require("pacman")) {
  install.packages("pacman")
}

pacman::p_unload("all") # Unloading all package except base

pacman::p_load(tidyverse, 
               janitor, 
               gt, 
               gtsummary, 
               flextable, 
               kableExtra, 
               skimr, 
               Hmisc, 
               readxl, 
               rstatix) # Loading packages

# icons::download_fontawesome()
```

```{r}
#| echo: false
library(haven)
datos <- read_dta("maca_meno_fase1.dta") %>% 
  as_factor() %>% 
  filter(time == "3 months")
```

## Pruebas de Hipótesis {.scrollable}

```{mermaid}
flowchart TD
  A[Pruebas de Hipótesis] --> B{Supuestos?}
  B -->|Sí| C[Parámetrica]
  B -->|No| D[No Paramétrica]
  D --> E{IC o Dif. Medias?}
  E -->|No| F[Rangos]
  E -->|Sí| G[Remuestreo]
```

## Pruebas de Hipótesis Paramétricas {.scrollable}

```{mermaid}
flowchart TD
  A[Pruebas de Hipótesis Paramétricas] --> B[Para Medias] --> C{1 Grupo?}
  C --> |Sí| C0[Prueba t de Student\n para 1 grupo]
  C --> |No| D{Dependencia?} --> D1[Independencia]
  D --> D2[Dependencia]
  D1 --> E1[2 grupos] --> H1[t de Student para \n2 grupos independientes]
  D1 --> E2[3 grupos] --> I1[Análisis de varianza \nde una vía]
  D2 --> G1[2 grupos] --> H2[t de Student para \n2 grupos dependientes]
  D2 --> G2[3 grupos] --> I2[Extensiones del \nAnálisis de Varianza]
```

## Pruebas de Hipótesis No Paramétricas {.scrollable}

```{mermaid}
flowchart TD
  A[Pruebas de Hipótesis \nNo Paramétricas\n Basadas en Rangos] --> B[Para Medianas] --> B1{1 grupo?}
  B1 -->|Sí| B2[Prueba del Signo]
  B1 -->|No| C{Dependencia?} 
  C --> D1(Independientes)
  C --> D2(Dependientes)
  D1 --> N2(2 grupos) --> F[Prueba de \nU Mann Whitney]
  D1 --> N3(3 grupos) --> G[Prueba de \nKruskal Wallis]
  D2 --> M2(2 grupos) --> F2[Prueba \ndel Signo]
  M2 --> F3[Prueba de Rangos \nSignados de Wilcoxon]
  D2 --> M3(3 grupos) --> G2[Prueba de \nFriedman]
```

## ¿De qué depende la PH que debo elegir? {.scrollable}

- `Datos` proporcionan `evidencia empírica` de alinearse con los `supuestos estadísticas` de la prueba elegida.

- 'Alinearse' quiere decir, `aproximarse 'razonablemente' bien`: 

>*“Todos los modelos son erróneos, pero algunos son útiles”. (George Box)*

- Tener en cuenta, que las `pruebas de hipótesis nula de significancia` tradicionales son `robustas` a `incumplimientos` de algunos `supuestos`.

## ¿De qué depende la PH que debo elegir? (cont.) {.scrollable}

- Por ejemplo, las `pruebas` mencionadas son `robustas` a `incumplimiento leve/moderado de normalidad` si y solo si el `n` es `suficientemente grande`.

- Sin embargo, ante el `incumplimiento`, hay que hacer un `análisis concienzudo` para tomar una decisión:

><FONT size='6'>**Opción 1:** Usar la prueba a pesar de leves/moderadas de algún supuesto porque la prueba es robusta ante este incumplimiento. </FONT>

><FONT size='6'>**Opción 2:** Usar otra prueba o la misma prueba 'corregida' que sí permita analizar apropiadamente los datos que tengo.</FONT>

## Supuestos comunes a todas las PH

- 1. Aleatorización

- 2. Observaciones independientes

## Aleatorización

![](images/aleatorizacion.png)

## Aleatorización {.scrollable}

- **`Muestra es aleatoria`** para `generalizar` a una `población` de interés `bien definida`. 

    + <FONT size='6'>Gold estándar: `Muestreo aleatorio simple` para alcanzar `"Representatividad Estadística"`.</FONT>
      
    + <FONT size='6'>Alternativas más limitadas: Muestreo consecutivo, otras formas de muestreo no probabilístico y asumir `"representatividad teórica"`.</FONT>

<center>`ó`</center>

- **`Muestra proviene de intervenciones asignadas por azar`** para hacer `inferencia causal` sobre una `intervención/exposición` de interés `bien definida`. 

    + <FONT size='6'>Gold estándar: `Asignación aleatoria`.</FONT>
    
    + <FONT size='6'>Alternativas más limitadas: Control de confusión y asumir `"emulación de asignación aleatoria"`.</FONT>

## 

:::{.callout-note}

## Los supuestos no verificables de la investigación clínica

- La mayoría de la `investigación clínica` recae en `supuestos no verificables`. 

- Cuando no hay `muestreo aleatorio` o `asignación aleatoria`, existe `riesgo alto` de que el supuesto no se cumpla.

- Sin embargo, en ciertos escenarios, `puede` ser `razonable pensar` que se `alcanzó el supuesto` (`representatividad teórica` o `emulación de asignación aleatoria`).

- En estos escenarios, estos `supuestos` son `no testeables completamente`, solo `parcialmente`:

    + <FONT size='5'>Solo podemos `refultarlos` con los `datos observados`, pero nunca probar su cumplimiento.</FONT>
    + <FONT size='5'>El investigador `asume una postura` y se `compremete`, temporalmente, con los `supuestos` hasta disponer de `mejor evidencia` y `actualizar` sus `posturas`.</FONT>
:::

## 

:::{.callout-note}

## La ausencia del muestreo probabilístico no siempre es mala

- `Siempre que sea posible`, debería optarse por las `formas más robustas` de hacer `inferencia`. 

    + <FONT size='5'>`Solo cuando sea imposible` (ej., muestreo aleatorio de pacientes, asignar una exposición dañina, etc) nos queda usar las formas `menos robustas`. </FONT>
    + <FONT size='5'>Dado que, `bajo ciertas condiciones`, se pueden obtener `inferencias válidas`, es `posible responder` preguntas con estos enfoques menos robustos aunque el `proceso` es `más largo` y `controvertido` (ej. efecto dañino del cigarro, del petroleo con plomo, cambio climático). </FONT>

- Algunas formas de `muestreo no probabilístico`, bajo ciertas condiciones, pueden razonablemente alcanzar `representatividad teórica`. La discusión transparente y sincera es importante.

    + <FONT size='5'>Por ejemplo, guías de riesgo de sesgo de estudios de prueba diagnóstica (como [QUADAS-2](https://pubmed.ncbi.nlm.nih.gov/22007046/)) considera al `muestreo consecutivo` en el mismo nivel que el muestreo probabilístico en contextos clínicos cuando no es factible realizar muestreo aleatorio para estudios de pruebas diagnósticas.</FONT>
    
:::

##

:::{.callout-warning}

## Advertencia: Abuso de la representatividad teórica!

- En `investigación clínica` a menudo se abusa de la `representividad teórica`.  

- Esto debería evitarse y reservarse solo a casos en los que resulta imposible hacer un muestreo aleatorio (y obtener `representatividad estadística`) pero se tenga algún procedimiento `no probabilístico` que pueda, bajo ciertas asunciones razonables, emular la representatividad estadística. 

- Un ejemplo clásico es usar un `muestreo consecutivo` (bien realizado) en ensayos clínicos, estudios de prueba diagnóstica o pronóstica. Este procedimiento es aceptado en ámbitos clínicos dado que no existe un marco muestral observable o se desea generalizar a nuevos pacientes (idea de superpobación). 

:::

## ¿Qué pasa si supuesto de Aleatoridad no se cumple?

- Incluso `sin una muestra probibilística` o una `asignación aleatoria`, la `aleatoridad` **`debe`** cumplirse.

- Por eso es que asumimos que se cumple cuando es `razonable hacerlo`. Si `no es razonable`, mejor **`no hacer el estudio`**.

    - <FONT size='6'>Si este supuesto en realidad no es cierto, su incumplimiento `invalida` las `inferencias` realizadas: No inferencias causales válidas, tampoco resultados generalizables a poblaciones de interés.</FONT>
    
## Observaciones son independientes

- Esto es equivalente a pensar que `todos los sujetos son muestreados de la misma población` y que han sido `seleccionados` de manera `independiente` de los otros.

    - <FONT size='6'>La selección de un individuo no afecta la selección de otro.</FONT>

- `¿Cuándo falla la independencia de observaciones?` 
    - <FONT size='6'>Cuando hay `pareamiento` o `correlación` debido al `tiempo`, `distribución espacial`, etc.</FONT>
    
## 

:::{.callout-note}

## ¿Se puede evaluar este supuesto?

- Sí se puede cuando se conoce la(s) variable(s) que generan la `dependencia`.

- A menudo `no se evalúa`, si no que uno lo antepone por el `diseño`.

- Los `métodos convencionales` se pueden `extender` para `lidiar` con `observaciones dependientes`.
    
:::

## Supuestos específicos de algunas PH

- 3. Normalidad 

- 4. Homogenenidad de varianzas (homocedasticidad)

## Normalidad

- Común en el caso de `pruebas paramétricas`: prueba t de Student, prueba Z y ANOVA.

- En realidad, requerimos que la `distribución muestral` del `estadístico` (p. ej., medias, proporciones, diferencia de medias, etc.) sea `normal`, `no` la `distribución de la variable`.


## Normalidad (cont.) 
- Se alcanza si la `distribución de la variable respuesta` es `normal`.

- Si la distribución de la `variable respuesta no es normal`, pero la `muestra` es `suficientemente grande` ($n \to \infty$), entonces la `distribución muestral de medias` es `normal`: `Teorema del Límite Central` garantiza `normalidad asintótica`.

## La idea en un Tweet! 

```{r}
#| echo: false
#| fig-align: center
knitr::include_graphics("images/normality.png")
```

## Normalidad asintótica de la distribución muestral {.scrollable}

```{mermaid}
flowchart TD
  A{Tamaño de muestra N}
  A --> B[Pequeño]
  A --> C[Suficientemente grande]
  B --> D{Normalidad en \nvariable respuesta?}
  C --> E{Normalidad en \nvariable respuesta?}
  D --> |Sí| F[Normalidad de \ndistribución muestral \ngarantizada]
  D --> |No| G[No normalidad\n supuesto incumplido] 
  E --> |Sí| I[Normalidad de \ndistribución muestral \ngarantizada]
  E --> |Desviación leve a moderada| J[Normalidad asintótica por \nTeorema del Límite Central]
  E --> |Desviación severa| K[Incierto si se \nalcanza normalidad]
  F --> L[[Optar por \n prueba paramétrica]]
  G --> M[[Optar por \nalternativa robusta]]
  I --> N[[Optar por \n prueba paramétrica]]
  J --> O[[Optar por \n prueba paramétrica]]
  K --> P[[Optar por \nalternativa robusta]]
```

## 

:::{.callout-warning}

## Advertencia: ¿Cuándo una muestra es suficientemente grande?

- Si la muestra es `pequeña`, es `muy importante` que la `población` tenga un `distribución normal` para que el supuesto de cumpla.

- Si la muestra es `suficientemente grande`, las inferencias serán `robustas` a `desviaciones ligeras/moderadas` del supuesto de normalidad.

- Problema: ¿Cuándo la muestra es `suficientemente` grande?

- Incluso con muestras consideradas `muy grandes` si distribución es `sesgada`, puede no alcanzarse la distribución normal.

- Ante la duda, mejor usar `métodos robustos` de manera complementaria (`análisis de sensibilidad`) o como `análisis principal`. 

:::

## ¿Cómo evaluar normalidad?

- La normalidad es sobre la población, no sobre la muestra.

- Sin embago, usamos a lo observado en la muestra para concluir sobre la población. 

- Métodos gráficos son preferibles: gráfico de qqplot.

- Métodos de prueba de hipótesis pueden complementar en tamaños de muestras moderados. Nunca usar solos!

## ¿Cómo evaluar normalidad? (cont.) {.scrollable}

::: panel-tabset 

### Método gráfico

- Preferible.

- Histogramas tienen problemas con pocos datos

- Usar gráfico de quantil quantil normal (QQ plot normal), es muy útil con pocos datos.

- Bandas de confianza son referenciales. Ayudan pero tener cuidado con muestras muy muy grandes.

- La función `ggqqplot` del paquete `{ggpubr}` es muy útil para esto:

**¿Qué distribución tiene?**

```{r}
#| echo: false
set.seed(123)
datos2 <- data.frame(
  x = rnorm(53, 100, 5), 
  grupo = c(rep("Control", 26), rep("Tratado", 27))
)
```

```{r}
library(ggpubr)
datos2 %>% 
    ggqqplot(x = "x")
```

> **Rpta.:** La variable x en la muestra tiene una distribución aproximadamente normal. Luego, concluyo que en la población la distribución de la variable x también debería ser normal y, por tanto, la distribución muestral de medias también debería ser normal. 

**¿Qué distribución tiene esta otra variable?**

```{r}

datos %>% 
  ggqqplot(x = "weight")
```

> **Rpta.:** La variable x en la muestra tiene una distribución aproximadamente normal, con cierta desviación ligera hacia la derecha. Esto sugiere que la distribución de la población tampoco es normal. Sin embargo, si el n es grande, es razonable asumir que la distribución muestral del estadístico es normal. 

**¿Y esta otra, qué distribución tiene?**

```{r}
datos %>% 
  ggqqplot(x = "e2")
```


> **Rpta.:** LA variable x en la muestra tiene una distribución que dista bastante de la normal, con una marcada desviación hacia la derecha. Esto sugiere que la distribución de la población tampoco es normal. Sin embargo, en este caso también es incierto saber qué tan grande debe ser el n para que se cumpla el TLC. Sería mejor usar alguna alternativa robusta.

### Prueba de hipótesis

**x**: 

```{r}
datos2 %>% 
  shapiro_test(x)
```
> **H0:** La distribucion de la variable en la poblacion es normal.
> **Ha:** La distribucion de la variable en la poblacion no es normal.
> **Conclusión:** Con un nivel de significancia del 5%, no se puede rechazar la H0. La distribución de la variable en la población podría ser normal.

**weight**: 

```{r}
datos %>% 
  shapiro_test(weight)
```
> **H0:** La distribucion de la variable en la poblacion es normal.
> **Ha:** La distribucion de la variable en la poblacion no es normal.
> **Conclusión:** Con un nivel de significancia del 5%, se rechaza la H0. La distribución de la variable en la población no es normal.
> **Comentario:** Según la evidencia gráfica, esta desviación es ligera, por lo que podríamos confiar en la normalidad asintótica.

**e2**: 

```{r}
datos %>% 
  shapiro_test(e2)
```
> **H0:** La distribucion de la variable en la poblacion es normal.
> **Ha:** La distribucion de la variable en la poblacion no es normal.
> **Conclusión:** Con un nivel de significancia del 5%, se rechaza la H0. La distribución de la variable en la población no es normal.

:::

## Homogeneidad de varianzas

- Consiste en que la `varianza` de la variable en `cada grupo` a comparar tiene el `mismo valor`. 

![](images/homogeneidad.png)


## Homogeneidad de varianzas (cont.)

- Muchas pruebas (t de Student, ANOVA, etc.) requieren el `cumplimiento` de este `supuesto` para poder dar inferencias válidas de `comparación de grupos`.

- Su `incumplimiento` `invalida` la `inferencia`: No se puede confiar en los `valores p` e `IC95%`.

- Lo bueno es que, a menudo, estas pruebas presentan `modificaciones` o correcciones que permiten obtener `inferencias robustas`.


## ¿Cómo evaluar homogeneidad de varianzas? {.scrollable}

::: panel-tabset 

### Método gráfico

- Actualmente son considerados `preferibles`. 

- Se pueden comparar los gráficos cuantil - cuantil normal.

- Si hay homocedasticidad, las líneas diagonales deberían ser paralelas o aproximadamente paralelas.

**¿Hay homogeneidad de varianzas?**

```{r}
datos2 %>% 
  ggqqplot("x", color = "grupo")
```

> **Rpta:** Sí hay evidencia gráfica de homocedasticidad en la muestra (líneas paralelas), luego, debería concluyo que también habría en las poblaciones.

**¿Y en este otro, hay homogeneidad de varianzas?**

```{r}
#| echo: false
set.seed(123)
datos3 <- data.frame(
  y = c(rnorm(26, 100, 5),rnorm(27, 100, 10)), 
  grupo = c(rep("Control", 26), rep("Tratado", 27))
)
```

```{r}
datos3 %>% 
  ggqqplot("y", color = "grupo")
```

> **Rpta:** No,  hay evidencia gráfica de heterocedasticidad en la muestra (líneas secantes), luego, debería concluyo que también habría heterogeneidad de varianzas en las poblaciones.

### Prueba de hipótesis

- Existen varias pruebas de hipótesis: Leven, Breslow, etc.

- El `principal problema` es que `no funcionan` bien con `n` muy `grandes` (siempre rechazan la H0) o muy `pequeños` (siempre aceptan la H0).

- Además requieren `supuestos` como la normalidad, entre otros.

- `Pueden` usarse de manera `complementaria` a los gráficos, pero `nunca solos`.

- No las abordaremos en este curso. Preferiremos el método gráfico.

:::


## Supuestos 'implícitos' de todas las PH

- 5. Datos medidos sin error 

- 6. No existencia de sesgo (error sistemático)


## Pruebas de Hipótesis con R 

- Existen `distintos paquetes` en R base para realizar `PH` o `estimación`.

- Hay mucha `inconsistencia` entre estos.

- El paquete `{rstatix}` compila todos estos en una sola sintaxis `R tidy`. 

```{r}
# install.packages("rstatix")
library(rstatix)
```

- Enlace web: [https://rpkgs.datanovia.com/rstatix/](https://rpkgs.datanovia.com/rstatix/)


# Estimación y Pruebas de Hipótesis para Variables Respuesta Numéricas

## Para un grupo {.scrollable}

::: panel-tabset

### Param. 1

- Se usa función `t_test()` de paquete `{rstatix}`.

- Permite obtener el `valor p` para una hipótesis dada y el `intervalo de confianza` para la `media`.

```{r}
datos %>% 
  t_test(weight ~ 1, mu = 100, detailed = TRUE) 
```

- El argumento `mu = número` es un valor de referencia contra el que deseamos compararnos.

- El argumento `detailed = TRUE` permite obtener también los `intervalos de confianza`. 

- La función `gt()` es para mejorar visualización del resultado. 

```{r}
library(gt)
datos %>% 
  t_test(weight ~ 1, mu = 100, detailed = TRUE) %>% 
  gt()
```

- Agregaremos gt() a partir de ahora.

- **Interpretación:**

> La media estimada de glucosa fue de 95.48 mg/dL (IC95% 71.6 mg/dL a 119.4 mg/dL). Aunque este valor fue menor a 100 mg/dL (valor de referencia), no es posible concluir que la media poblacional es diferente del valor de refrencia 100 mg/dL (p = 0.627).

:::{.callout-note}

## Supuestos

- Aleatorización

- Indenpendencia de observaciones

- Normalidad o cumplimiento del TLC.

```{r}
library(ggpubr)
datos %>% 
  ggqqplot(x = "weight")
```

- Supuesto de homogeneidad de varianzas (homocedasticidad) no importa aquí ya que solo hay 1 grupo!

- Supuestos implícitos (no error de medición ni sesgos)

:::

### Param. 2

**¿El nivel medio de estradiol es difernete de 50 UI en la población?**

Para variable estradiol:

```{r}
datos %>% 
  t_test(e2 ~ 1, mu = 50, detailed = TRUE) 
```

:::{.callout-note}

Supuestos: 

- Aleatorización

- Indenpendencia de observaciones

- Normalidad o cumplimiento del TLC.

```{r}
datos %>% 
  ggqqplot(x = "e2")
```

- Supuesto de homogeneidad de varianzas (homocedasticidad) no importa aquí ya que solo hay 1 grupo!

- Supuestos implícitos (no error de medición ni sesgos)

:::

- **Interpretación:**

> La media estimada de estradiol fue de 112.67 UI. Debido a la desviación severa de la normalidad, preferimos no confiar en la inferencia generada por la prueba de hipótesis t de Student y obtamos por una alternativa robusta no parmétrica. 

### No Param 1 

**Prueba del Signo**:

- Permite comparar la `mediana` (ya no la media) contra un valor de referencia.

- No permite estimar intervalos de confianza.

```{r}
datos %>% 
  sign_test(weight ~ 1, mu = 0, detailed = TRUE) 
```

- **Interpretación:**

> La mediana estimada de glucosa fue de 95.53 mg/dL. Aunque este valor fue menor a 100 mg/dL (valor de referencia), no es posible concluir que la media poblacional es diferente del valor de refrencia (p = 0.627).

:::{.callout-note}

## Supuestos

- Aleatorización

- Indenpendencia de observaciones

- Variable al menos en escala ordinal

- Supuestos implícitos (no error de medición ni sesgos)

::: 

### No Param 2 

**¿El nivel mediano de estradiol es difernete de 50 UI en la población?**

```{r}
datos %>% 
  sign_test(e2 ~ 1, mu = 50, detailed = TRUE) 
```

:::{.callout-note}

## Supuestos

- Aleatorización

- Indenpendencia de observaciones

- Variable al menos en escala ordinal

- Supuestos implícitos (no error de medición ni sesgos)

::: 


- **Interpretación:**

> La mediana estimada de estradiol fue de 103.95 UI. Este valor fue mayor a 50 UI (valor de referencia) (p < 0.001).

:::

## Estimación y PH para dos grupos dependientes {.scrollable}

::: panel-tabset

### Paramétrico

- Se usa la `prueba t de Student` para datos pareados. 

- Como los datos están pareados 1:1, la prueba trabaja sobre la `diferencia de los valores` individuales convirtiendo el problema en `una sola muestra`. 

- Por lo tanto, los `supuestos` son los `mismos` que para la `prueba t de Student  de un solo grupo.

**Ejemplo:** ¿Cuál es el efecto de la Vitamina C en el crecimiento de los dientes en cuyes experimentales?

`len`: Longitud de dientes al final del experimento.

`supp`: Suplemento de vitamina C (VC vs. OJ)

```{r}
#| echo: false
data("ToothGrowth")
df <- ToothGrowth
read.csv("df3.csv", sep = ";") -> df2

df2 %>% 
  mutate(dif = VC - OJ) -> df3
```

```{r}
df %>% t_test(len ~ supp, 
              paired = TRUE, 
              detailed = TRUE) %>% gt()
```

:::{.callout-important}

## Supuestos

- Aleatorización

- Indenpendencia de observaciones

- Normalidad o cumplimiento del TLC.

```{r}
library(ggpubr)
df3 %>% 
  ggqqplot(x = "dif")
```

- Variable al menos en escala ordinal

- Supuestos implícitos (no error de medición ni sesgos)

:::

### No param.

- Se tienen dos opciones: `Prueba del signo` vs. `Prueba de rangos signados de Wilcoxon`.

- Se trabaja igual que para t-test pareada, con al `diferencia de los valores` de tal forma que se tiene solo `un grupo`.

- `Prueba del signo` no requiere supuesto de simetría de distribución para comparar medianas.

- `Prueba de Wilcoxon` requiere supuesto de simetría de distribución para comparar medianas. 

**Prueba del signo:**

```{r}
df %>% sign_test(len ~ supp, 
              detailed = TRUE) %>% gt()
```

**Prueba de Wilcoxon:**

```{r}
df %>% wilcox_test(len ~ supp, 
              detailed = TRUE) %>% gt()
```

:::{.callout-important}

## Supuestos de la Prueba del Signo

- Aleatorización

- Indenpendencia de observaciones

- Escala de medición al menos ordinal

:::

:::{.callout-important}

## Supuestos de la Prueba de Wilcoxon

- Aleatorización

- Indenpendencia de observaciones

- Escala de medición al menos ordinal

- Distribución simétrica

:::

:::

## Estimación y PH para dos grupos independientes {.scrollable}

::: panel-tabset

### Paramétrico

- Se usa `prueba t de Student` para `grupos independientes`.

```{r}
datos2 <- datos %>% 
  filter(treat != "WARMI 3 C/D") %>% 
  mutate(treat = droplevels(treat))
```

```{r}
datos2 %>% 
  t_test(weight ~ treat, detailed = TRUE, var.equal = TRUE) %>% 
  gt()
```

:::{.callout-important}

## Supuestos de la Prueba t de Student para grupos independientes

- Aleatorización

- Indenpendencia de observaciones

- Normalidad

- Homogeneidad de varianzas (*)

```{r}
datos2 %>% 
  ggqqplot("weight", color = "treat")
```

```{r}
datos2 %>% 
  group_by(treat) %>% 
  skim(weight)
```

- Si no confiamos en la homogeneidad de varianzas, podemos hacer la prueba robusta a la heterogeneidad de varianzas usando la corrección de Satterwhite:

```{r}
datos2 %>% 
  t_test(weight ~ treat, detailed = TRUE, var.equal = FALSE) %>% 
  gt()
```

:::

### No param.

- Se usa `prueba de suma de rangos de Wilcoxon`, también denominada `U de Mann Withney`.

```{r}
datos2 %>% 
  wilcox_test(e2 ~ treat, detailed = TRUE) %>% 
  gt()
```

:::

:::{.callout-important}

## Supuestos

- Aleatorización

- Indenpendencia de observaciones

- Escala de medición al menos ordinal

- Igual forma de distribución entre los grupos (solo diferencia en la posición)

:::

# Pruebas de hipótesis para variables respuesta categóricas


## Prueba Chi cuadrado {.scrollable}

```{r}
datos2 %>% 
  tbl_cross(
    row = married2,
    col = treat, 
    percent = "row"
  ) %>% 
  add_p()
```


## Prueba exacta de Fisher {.scrollable}

```{r}
datos2 %>% 
  tbl_cross(
    row = married2,
    col = treat, 
    percent = "row"
  ) %>% 
  add_p(
     test = "fisher.test"
  )
```


## Creación de tablas reproducibles con gtsummary {.scrollable}

```{r}
library(gtsummary)
datos2 %>%
  dplyr::select(treat, age, weight, e2, fsh, lh, race, married) %>% 
  tbl_summary(
    by = treat
  ) %>%  
  add_p()
```

## Recomendaciones {.scrollable}

- `No reporte valores p innecesarios`, que no respondan sus preguntas de investigación pre-definidas.

- Es una `mala práctica` reportar tablas comparativas descriptivas con valores p. Lamentablemente es muy difundida.

- Varias guías, comenzando por `STROBE` (para observacionales) y `CONSORT` (para ensayos clínicos) explícitamente recomiendan en contra de reportar estas tablas. Solo haga una comparación descriptiva de los resultados de la tabla. 

::: r-fit-text
<br>

<center>

slides:

</center>

<center>

[https://bit.ly/3n6Ejzb](https://ietsi-academy-aed.netlify.app/sesiones/sesion-1/sesion-1c)

</center>
:::

## 

::: r-fit-text
<center>**¡Gracias por su atención!**</center>
<center>**¡Encantado de responder sus consultas!**</center>

<br>

<center>**Percy Soto-Becerra**</center>

<br>

<center>`r icons::fontawesome$brands$twitter` `r icons::fontawesome$brands$github` @psotob91</center>
<center>`r icons::fontawesome$solid$inbox` **percys1991\@gmail.com**</center>
:::

::: aside
<br> <FONT size='4'>Presentación creada vía `Revealjs` en `Quarto` en `RStudio`.</FONT>
:::
